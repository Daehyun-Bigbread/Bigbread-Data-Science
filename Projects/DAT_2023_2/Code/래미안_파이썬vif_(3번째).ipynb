{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RTL1I2pcbL4M"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. 데이터 로드**"
      ],
      "metadata": {
        "id": "0awBdZoXbS1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPVlJo6qbVJI",
        "outputId": "ee8e2c79-4d6f-4bbe-dfa5-ceb1b94915b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuBkNPCJbXlX",
        "outputId": "4d71411c-87aa-4786-ed6c-efd7db9559d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('house_data.csv')"
      ],
      "metadata": {
        "id": "rqZLwCA7bZpy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['단지명', '매칭 구']] = data[['매칭 구', '단지명']]\n",
        "data = data.rename(columns = {'단지명':'매칭 구', '매칭 구':'단지명'})\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cL2r6MW_bbmn",
        "outputId": "8ab540ef-baff-4cbb-a3e8-3e9d6cf458bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     매칭 구  전용면적(㎡)    계약년월  계약일 거래금액(만원)   층  건축년도  도로명        단지명  \\\n",
              "0     강남구    74.66  202101   17  245,000   7  2020  개포로  개포래미안포레스트   \n",
              "1     강남구    59.92  202105   22  198,500  18  2020  개포로  개포래미안포레스트   \n",
              "2     강남구    49.92  202105   22  180,000   7  2020  개포로  개포래미안포레스트   \n",
              "3     강남구    59.92  202105   22  198,500  18  2020  개포로  개포래미안포레스트   \n",
              "4     강남구    49.92  202105   22  180,000   7  2020  개포로  개포래미안포레스트   \n",
              "...   ...      ...     ...  ...      ...  ..   ...  ...        ...   \n",
              "7857   중구    59.74  202011   28  104,000   5  2011  퇴계로    래미안하이베르   \n",
              "7858   중구    59.74  202012    1  102,000   5  2011  퇴계로    래미안하이베르   \n",
              "7859   중구    59.74  202012    5  106,000  13  2011  퇴계로    래미안하이베르   \n",
              "7860   중구    84.98  202012   10  128,000   2  2011  퇴계로    래미안하이베르   \n",
              "7861   중구    84.97  202012   16  126,500  10  2011  퇴계로    래미안하이베르   \n",
              "\n",
              "     건설수주_건축(단위 백만원)  ... 경제활동인구_고용률(단위: %)  경제활동인구_취업자(단위: 천명)  \\\n",
              "0         10,589,107  ...              57.4              25,818   \n",
              "1         11,699,841  ...              61.2              27,550   \n",
              "2         11,699,841  ...              61.2              27,550   \n",
              "3         11,699,841  ...              61.2              27,550   \n",
              "4         11,699,841  ...              61.2              27,550   \n",
              "...              ...  ...               ...                 ...   \n",
              "7857      13,510,590  ...              60.7              27,241   \n",
              "7858      22,231,493  ...              59.1              26,526   \n",
              "7859      22,231,493  ...              59.1              26,526   \n",
              "7860      22,231,493  ...              59.1              26,526   \n",
              "7861      22,231,493  ...              59.1              26,526   \n",
              "\n",
              "     국제 주요국 주가지수(KOSPI) 예금은행 대출금리(신규취급액 기준)_대출평균(연%)  \\\n",
              "0              2,976.21                         2.72   \n",
              "1              3,203.92                         2.72   \n",
              "2              3,203.92                         2.72   \n",
              "3              3,203.92                         2.72   \n",
              "4              3,203.92                         2.72   \n",
              "...                 ...                          ...   \n",
              "7857           2,591.34                         2.71   \n",
              "7858           2,873.47                         2.74   \n",
              "7859           2,873.47                         2.74   \n",
              "7860           2,873.47                         2.74   \n",
              "7861           2,873.47                         2.74   \n",
              "\n",
              "     예금은행 대출금리(잔액 기준)_총대출(연리%) 주택매매가격지수(KB)_서울 소비자물가지수_총지수(가중치:1000?)  \\\n",
              "0                         2.80          89.828                 101.04   \n",
              "1                         2.78          93.144                 102.05   \n",
              "2                         2.78          93.144                 102.05   \n",
              "3                         2.78          93.144                 102.05   \n",
              "4                         2.78          93.144                 102.05   \n",
              "...                        ...             ...                    ...   \n",
              "7857                      2.81          87.613                 100.09   \n",
              "7858                      2.80          88.701                 100.33   \n",
              "7859                      2.80          88.701                 100.33   \n",
              "7860                      2.80          88.701                 100.33   \n",
              "7861                      2.80          88.701                 100.33   \n",
              "\n",
              "      원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원  경기종합지수          평당가  \n",
              "0                               1,099.03   103.8  3281.542995  \n",
              "1                               1,123.39   106.3  3312.750334  \n",
              "2                               1,123.39   106.3  3605.769231  \n",
              "3                               1,123.39   106.3  3312.750334  \n",
              "4                               1,123.39   106.3  3605.769231  \n",
              "...                                  ...     ...          ...  \n",
              "7857                            1,115.20   102.6  1740.877134  \n",
              "7858                            1,094.50   103.1  1707.398728  \n",
              "7859                            1,094.50   103.1  1774.355541  \n",
              "7860                            1,094.50   103.1  1506.236762  \n",
              "7861                            1,094.50   103.1  1488.760739  \n",
              "\n",
              "[7862 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2106ce8-5a07-413b-b7ad-903898b2ea15\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>매칭 구</th>\n",
              "      <th>전용면적(㎡)</th>\n",
              "      <th>계약년월</th>\n",
              "      <th>계약일</th>\n",
              "      <th>거래금액(만원)</th>\n",
              "      <th>층</th>\n",
              "      <th>건축년도</th>\n",
              "      <th>도로명</th>\n",
              "      <th>단지명</th>\n",
              "      <th>건설수주_건축(단위 백만원)</th>\n",
              "      <th>...</th>\n",
              "      <th>경제활동인구_고용률(단위: %)</th>\n",
              "      <th>경제활동인구_취업자(단위: 천명)</th>\n",
              "      <th>국제 주요국 주가지수(KOSPI)</th>\n",
              "      <th>예금은행 대출금리(신규취급액 기준)_대출평균(연%)</th>\n",
              "      <th>예금은행 대출금리(잔액 기준)_총대출(연리%)</th>\n",
              "      <th>주택매매가격지수(KB)_서울</th>\n",
              "      <th>소비자물가지수_총지수(가중치:1000?)</th>\n",
              "      <th>원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원</th>\n",
              "      <th>경기종합지수</th>\n",
              "      <th>평당가</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>강남구</td>\n",
              "      <td>74.66</td>\n",
              "      <td>202101</td>\n",
              "      <td>17</td>\n",
              "      <td>245,000</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>개포로</td>\n",
              "      <td>개포래미안포레스트</td>\n",
              "      <td>10,589,107</td>\n",
              "      <td>...</td>\n",
              "      <td>57.4</td>\n",
              "      <td>25,818</td>\n",
              "      <td>2,976.21</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.80</td>\n",
              "      <td>89.828</td>\n",
              "      <td>101.04</td>\n",
              "      <td>1,099.03</td>\n",
              "      <td>103.8</td>\n",
              "      <td>3281.542995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>강남구</td>\n",
              "      <td>59.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>198,500</td>\n",
              "      <td>18</td>\n",
              "      <td>2020</td>\n",
              "      <td>개포로</td>\n",
              "      <td>개포래미안포레스트</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3312.750334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>강남구</td>\n",
              "      <td>49.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>180,000</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>개포로</td>\n",
              "      <td>개포래미안포레스트</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3605.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>강남구</td>\n",
              "      <td>59.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>198,500</td>\n",
              "      <td>18</td>\n",
              "      <td>2020</td>\n",
              "      <td>개포로</td>\n",
              "      <td>개포래미안포레스트</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3312.750334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>강남구</td>\n",
              "      <td>49.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>180,000</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>개포로</td>\n",
              "      <td>개포래미안포레스트</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3605.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7857</th>\n",
              "      <td>중구</td>\n",
              "      <td>59.74</td>\n",
              "      <td>202011</td>\n",
              "      <td>28</td>\n",
              "      <td>104,000</td>\n",
              "      <td>5</td>\n",
              "      <td>2011</td>\n",
              "      <td>퇴계로</td>\n",
              "      <td>래미안하이베르</td>\n",
              "      <td>13,510,590</td>\n",
              "      <td>...</td>\n",
              "      <td>60.7</td>\n",
              "      <td>27,241</td>\n",
              "      <td>2,591.34</td>\n",
              "      <td>2.71</td>\n",
              "      <td>2.81</td>\n",
              "      <td>87.613</td>\n",
              "      <td>100.09</td>\n",
              "      <td>1,115.20</td>\n",
              "      <td>102.6</td>\n",
              "      <td>1740.877134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7858</th>\n",
              "      <td>중구</td>\n",
              "      <td>59.74</td>\n",
              "      <td>202012</td>\n",
              "      <td>1</td>\n",
              "      <td>102,000</td>\n",
              "      <td>5</td>\n",
              "      <td>2011</td>\n",
              "      <td>퇴계로</td>\n",
              "      <td>래미안하이베르</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1707.398728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7859</th>\n",
              "      <td>중구</td>\n",
              "      <td>59.74</td>\n",
              "      <td>202012</td>\n",
              "      <td>5</td>\n",
              "      <td>106,000</td>\n",
              "      <td>13</td>\n",
              "      <td>2011</td>\n",
              "      <td>퇴계로</td>\n",
              "      <td>래미안하이베르</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1774.355541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7860</th>\n",
              "      <td>중구</td>\n",
              "      <td>84.98</td>\n",
              "      <td>202012</td>\n",
              "      <td>10</td>\n",
              "      <td>128,000</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>퇴계로</td>\n",
              "      <td>래미안하이베르</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1506.236762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7861</th>\n",
              "      <td>중구</td>\n",
              "      <td>84.97</td>\n",
              "      <td>202012</td>\n",
              "      <td>16</td>\n",
              "      <td>126,500</td>\n",
              "      <td>10</td>\n",
              "      <td>2011</td>\n",
              "      <td>퇴계로</td>\n",
              "      <td>래미안하이베르</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1488.760739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7862 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2106ce8-5a07-413b-b7ad-903898b2ea15')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2106ce8-5a07-413b-b7ad-903898b2ea15 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2106ce8-5a07-413b-b7ad-903898b2ea15');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8ed50e49-26d2-4807-aa83-5e845f5b399d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8ed50e49-26d2-4807-aa83-5e845f5b399d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8ed50e49-26d2-4807-aa83-5e845f5b399d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 도로명, 단지명 column 제거\n",
        "\n",
        "\n",
        "data = data.drop(['도로명', '단지명'], axis = 1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "YuNet6uKbkOW",
        "outputId": "df7edac5-bc83-42b7-e3be-d3b3918264b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     매칭 구  전용면적(㎡)    계약년월  계약일 거래금액(만원)   층  건축년도 건설수주_건축(단위 백만원)  \\\n",
              "0     강남구    74.66  202101   17  245,000   7  2020      10,589,107   \n",
              "1     강남구    59.92  202105   22  198,500  18  2020      11,699,841   \n",
              "2     강남구    49.92  202105   22  180,000   7  2020      11,699,841   \n",
              "3     강남구    59.92  202105   22  198,500  18  2020      11,699,841   \n",
              "4     강남구    49.92  202105   22  180,000   7  2020      11,699,841   \n",
              "...   ...      ...     ...  ...      ...  ..   ...             ...   \n",
              "7857   중구    59.74  202011   28  104,000   5  2011      13,510,590   \n",
              "7858   중구    59.74  202012    1  102,000   5  2011      22,231,493   \n",
              "7859   중구    59.74  202012    5  106,000  13  2011      22,231,493   \n",
              "7860   중구    84.98  202012   10  128,000   2  2011      22,231,493   \n",
              "7861   중구    84.97  202012   16  126,500  10  2011      22,231,493   \n",
              "\n",
              "     건설수주_주택(단위 백만원)  매매가격지수(아파트)  ... 경제활동인구_고용률(단위: %) 경제활동인구_취업자(단위: 천명)  \\\n",
              "0          6,436,523         97.0  ...              57.4             25,818   \n",
              "1          5,568,538         99.0  ...              61.2             27,550   \n",
              "2          5,568,538         99.0  ...              61.2             27,550   \n",
              "3          5,568,538         99.0  ...              61.2             27,550   \n",
              "4          5,568,538         99.0  ...              61.2             27,550   \n",
              "...              ...          ...  ...               ...                ...   \n",
              "7857       8,663,124         96.4  ...              60.7             27,241   \n",
              "7858      15,138,239         96.6  ...              59.1             26,526   \n",
              "7859      15,138,239         96.6  ...              59.1             26,526   \n",
              "7860      15,138,239         96.6  ...              59.1             26,526   \n",
              "7861      15,138,239         96.6  ...              59.1             26,526   \n",
              "\n",
              "     국제 주요국 주가지수(KOSPI) 예금은행 대출금리(신규취급액 기준)_대출평균(연%)  \\\n",
              "0              2,976.21                         2.72   \n",
              "1              3,203.92                         2.72   \n",
              "2              3,203.92                         2.72   \n",
              "3              3,203.92                         2.72   \n",
              "4              3,203.92                         2.72   \n",
              "...                 ...                          ...   \n",
              "7857           2,591.34                         2.71   \n",
              "7858           2,873.47                         2.74   \n",
              "7859           2,873.47                         2.74   \n",
              "7860           2,873.47                         2.74   \n",
              "7861           2,873.47                         2.74   \n",
              "\n",
              "     예금은행 대출금리(잔액 기준)_총대출(연리%)  주택매매가격지수(KB)_서울  소비자물가지수_총지수(가중치:1000?)  \\\n",
              "0                         2.80           89.828                  101.04   \n",
              "1                         2.78           93.144                  102.05   \n",
              "2                         2.78           93.144                  102.05   \n",
              "3                         2.78           93.144                  102.05   \n",
              "4                         2.78           93.144                  102.05   \n",
              "...                        ...              ...                     ...   \n",
              "7857                      2.81           87.613                  100.09   \n",
              "7858                      2.80           88.701                  100.33   \n",
              "7859                      2.80           88.701                  100.33   \n",
              "7860                      2.80           88.701                  100.33   \n",
              "7861                      2.80           88.701                  100.33   \n",
              "\n",
              "      원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원  경기종합지수          평당가  \n",
              "0                               1,099.03   103.8  3281.542995  \n",
              "1                               1,123.39   106.3  3312.750334  \n",
              "2                               1,123.39   106.3  3605.769231  \n",
              "3                               1,123.39   106.3  3312.750334  \n",
              "4                               1,123.39   106.3  3605.769231  \n",
              "...                                  ...     ...          ...  \n",
              "7857                            1,115.20   102.6  1740.877134  \n",
              "7858                            1,094.50   103.1  1707.398728  \n",
              "7859                            1,094.50   103.1  1774.355541  \n",
              "7860                            1,094.50   103.1  1506.236762  \n",
              "7861                            1,094.50   103.1  1488.760739  \n",
              "\n",
              "[7862 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf69bf6b-2f6b-4fea-a766-afd8d440bc3e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>매칭 구</th>\n",
              "      <th>전용면적(㎡)</th>\n",
              "      <th>계약년월</th>\n",
              "      <th>계약일</th>\n",
              "      <th>거래금액(만원)</th>\n",
              "      <th>층</th>\n",
              "      <th>건축년도</th>\n",
              "      <th>건설수주_건축(단위 백만원)</th>\n",
              "      <th>건설수주_주택(단위 백만원)</th>\n",
              "      <th>매매가격지수(아파트)</th>\n",
              "      <th>...</th>\n",
              "      <th>경제활동인구_고용률(단위: %)</th>\n",
              "      <th>경제활동인구_취업자(단위: 천명)</th>\n",
              "      <th>국제 주요국 주가지수(KOSPI)</th>\n",
              "      <th>예금은행 대출금리(신규취급액 기준)_대출평균(연%)</th>\n",
              "      <th>예금은행 대출금리(잔액 기준)_총대출(연리%)</th>\n",
              "      <th>주택매매가격지수(KB)_서울</th>\n",
              "      <th>소비자물가지수_총지수(가중치:1000?)</th>\n",
              "      <th>원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원</th>\n",
              "      <th>경기종합지수</th>\n",
              "      <th>평당가</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>강남구</td>\n",
              "      <td>74.66</td>\n",
              "      <td>202101</td>\n",
              "      <td>17</td>\n",
              "      <td>245,000</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>10,589,107</td>\n",
              "      <td>6,436,523</td>\n",
              "      <td>97.0</td>\n",
              "      <td>...</td>\n",
              "      <td>57.4</td>\n",
              "      <td>25,818</td>\n",
              "      <td>2,976.21</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.80</td>\n",
              "      <td>89.828</td>\n",
              "      <td>101.04</td>\n",
              "      <td>1,099.03</td>\n",
              "      <td>103.8</td>\n",
              "      <td>3281.542995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>강남구</td>\n",
              "      <td>59.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>198,500</td>\n",
              "      <td>18</td>\n",
              "      <td>2020</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>5,568,538</td>\n",
              "      <td>99.0</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3312.750334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>강남구</td>\n",
              "      <td>49.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>180,000</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>5,568,538</td>\n",
              "      <td>99.0</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3605.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>강남구</td>\n",
              "      <td>59.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>198,500</td>\n",
              "      <td>18</td>\n",
              "      <td>2020</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>5,568,538</td>\n",
              "      <td>99.0</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3312.750334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>강남구</td>\n",
              "      <td>49.92</td>\n",
              "      <td>202105</td>\n",
              "      <td>22</td>\n",
              "      <td>180,000</td>\n",
              "      <td>7</td>\n",
              "      <td>2020</td>\n",
              "      <td>11,699,841</td>\n",
              "      <td>5,568,538</td>\n",
              "      <td>99.0</td>\n",
              "      <td>...</td>\n",
              "      <td>61.2</td>\n",
              "      <td>27,550</td>\n",
              "      <td>3,203.92</td>\n",
              "      <td>2.72</td>\n",
              "      <td>2.78</td>\n",
              "      <td>93.144</td>\n",
              "      <td>102.05</td>\n",
              "      <td>1,123.39</td>\n",
              "      <td>106.3</td>\n",
              "      <td>3605.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7857</th>\n",
              "      <td>중구</td>\n",
              "      <td>59.74</td>\n",
              "      <td>202011</td>\n",
              "      <td>28</td>\n",
              "      <td>104,000</td>\n",
              "      <td>5</td>\n",
              "      <td>2011</td>\n",
              "      <td>13,510,590</td>\n",
              "      <td>8,663,124</td>\n",
              "      <td>96.4</td>\n",
              "      <td>...</td>\n",
              "      <td>60.7</td>\n",
              "      <td>27,241</td>\n",
              "      <td>2,591.34</td>\n",
              "      <td>2.71</td>\n",
              "      <td>2.81</td>\n",
              "      <td>87.613</td>\n",
              "      <td>100.09</td>\n",
              "      <td>1,115.20</td>\n",
              "      <td>102.6</td>\n",
              "      <td>1740.877134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7858</th>\n",
              "      <td>중구</td>\n",
              "      <td>59.74</td>\n",
              "      <td>202012</td>\n",
              "      <td>1</td>\n",
              "      <td>102,000</td>\n",
              "      <td>5</td>\n",
              "      <td>2011</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>15,138,239</td>\n",
              "      <td>96.6</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1707.398728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7859</th>\n",
              "      <td>중구</td>\n",
              "      <td>59.74</td>\n",
              "      <td>202012</td>\n",
              "      <td>5</td>\n",
              "      <td>106,000</td>\n",
              "      <td>13</td>\n",
              "      <td>2011</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>15,138,239</td>\n",
              "      <td>96.6</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1774.355541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7860</th>\n",
              "      <td>중구</td>\n",
              "      <td>84.98</td>\n",
              "      <td>202012</td>\n",
              "      <td>10</td>\n",
              "      <td>128,000</td>\n",
              "      <td>2</td>\n",
              "      <td>2011</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>15,138,239</td>\n",
              "      <td>96.6</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1506.236762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7861</th>\n",
              "      <td>중구</td>\n",
              "      <td>84.97</td>\n",
              "      <td>202012</td>\n",
              "      <td>16</td>\n",
              "      <td>126,500</td>\n",
              "      <td>10</td>\n",
              "      <td>2011</td>\n",
              "      <td>22,231,493</td>\n",
              "      <td>15,138,239</td>\n",
              "      <td>96.6</td>\n",
              "      <td>...</td>\n",
              "      <td>59.1</td>\n",
              "      <td>26,526</td>\n",
              "      <td>2,873.47</td>\n",
              "      <td>2.74</td>\n",
              "      <td>2.80</td>\n",
              "      <td>88.701</td>\n",
              "      <td>100.33</td>\n",
              "      <td>1,094.50</td>\n",
              "      <td>103.1</td>\n",
              "      <td>1488.760739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7862 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf69bf6b-2f6b-4fea-a766-afd8d440bc3e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf69bf6b-2f6b-4fea-a766-afd8d440bc3e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf69bf6b-2f6b-4fea-a766-afd8d440bc3e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec1f81a8-8212-4578-8ce1-ac76f11e935a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec1f81a8-8212-4578-8ce1-ac76f11e935a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec1f81a8-8212-4578-8ce1-ac76f11e935a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. EDA**"
      ],
      "metadata": {
        "id": "JOl6IwPubsTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-1. 데이터 타입 확인 및 변환\n",
        "\n",
        "  - 범주형 변수를 수치형으로 변환 (원핫인코딩 사용)\n",
        "\n",
        "2-2. 결측치 처리\n",
        "\n",
        "2-3. 이상치 처리\n",
        "\n",
        "  - 우리는 25% 위아래로 자르기로 함\n",
        "\n",
        "2-4. 스케일링\n",
        "\n",
        "  - 변수들의 범위를 일치시켜주기 위해서\n",
        "\n",
        "2-5. 다중공산성 확인을 위한 변수 선택\n",
        "\n",
        "  - 불필요한 변수 제거 미리 하고 vif 확인해준다.\n",
        "\n",
        "  - 파이썬의 경우 4개??\n",
        "\n",
        "2-6. 변수 변환 (로그 변환, 제곱근 변환 등)\n",
        "\n",
        "   - 이 경우, 타겟 값 자체가 꼬리부분이 엄청 긴 모양이 나오기 때문에 로그 변환시켜 정규분포로 만들어주었다."
      ],
      "metadata": {
        "id": "iM10Pldyb4-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-1. 원핫인코딩**\n",
        "\n",
        "- 데이터 타입이 object, category 인 것들 = 범주형 변수 => 원핫인코딩"
      ],
      "metadata": {
        "id": "MhNoo2RPc2Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLtys0Lcc5qW",
        "outputId": "e575a552-2b59-46ac-e56a-f36e537d243a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7862 entries, 0 to 7861\n",
            "Data columns (total 34 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   매칭 구                                7862 non-null   object \n",
            " 1   전용면적(㎡)                             7862 non-null   float64\n",
            " 2   계약년월                                7862 non-null   int64  \n",
            " 3   계약일                                 7862 non-null   int64  \n",
            " 4   거래금액(만원)                            7862 non-null   object \n",
            " 5   층                                   7862 non-null   int64  \n",
            " 6   건축년도                                7862 non-null   int64  \n",
            " 7   건설수주_건축(단위 백만원)                     7862 non-null   object \n",
            " 8   건설수주_주택(단위 백만원)                     7862 non-null   object \n",
            " 9   매매가격지수(아파트)                         7862 non-null   float64\n",
            " 10  경상수지(백만불)                           7862 non-null   object \n",
            " 11  무역수지(백만불)                           7862 non-null   object \n",
            " 12  대출금액(아파트)(억원)                       7862 non-null   object \n",
            " 13  대출잔액(아파트)(억원)                       7862 non-null   object \n",
            " 14  서울_신규_분양세대(단위: 세대)                  7862 non-null   object \n",
            " 15  아파트 동(호)수_(단위: 호)                   7862 non-null   int64  \n",
            " 16  아파트 건물면적_(천)                        7755 non-null   float64\n",
            " 17  생산자물가지수 총지수                         7862 non-null   float64\n",
            " 18  전규모(1인이상) 전체임금총액[원]                 7862 non-null   int64  \n",
            " 19  소비자물가지수 총지수                         7862 non-null   float64\n",
            " 20  소비자물가지수 주택, 수도, 전기 및 연료             7862 non-null   float64\n",
            " 21  가계대출 (연리%)                          7862 non-null   float64\n",
            " 22  경기종합지수(2020=100)                    7862 non-null   float64\n",
            " 23  경제활동인구_ 실업률(단위: %)                  7862 non-null   float64\n",
            " 24  경제활동인구_고용률(단위: %)                   7862 non-null   float64\n",
            " 25  경제활동인구_취업자(단위: 천명)                  7862 non-null   object \n",
            " 26  국제 주요국 주가지수(KOSPI)                  7862 non-null   object \n",
            " 27  예금은행 대출금리(신규취급액 기준)_대출평균(연%)        7862 non-null   float64\n",
            " 28  예금은행 대출금리(잔액 기준)_총대출(연리%)           7862 non-null   float64\n",
            " 29  주택매매가격지수(KB)_서울                     7862 non-null   float64\n",
            " 30  소비자물가지수_총지수(가중치:1000?)              7862 non-null   float64\n",
            " 31  원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원  7862 non-null   object \n",
            " 32  경기종합지수                              7862 non-null   float64\n",
            " 33  평당가                                 7862 non-null   float64\n",
            "dtypes: float64(16), int64(6), object(12)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "object_columns = data.select_dtypes(include=['object']).columns\n",
        "print(object_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO5OhwUlewYw",
        "outputId": "b2968450-345b-419a-f8d8-6f83c8e1f09b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['매칭 구', '거래금액(만원)', '건설수주_건축(단위 백만원)', '건설수주_주택(단위 백만원)', '경상수지(백만불)',\n",
            "       '무역수지(백만불)', '대출금액(아파트)(억원)', '대출잔액(아파트)(억원)', '서울_신규_분양세대(단위: 세대)',\n",
            "       '경제활동인구_취업자(단위: 천명)', '국제 주요국 주가지수(KOSPI)',\n",
            "       '원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "object = 매칭구, 거래금액(만원), 건설수주_건축(단위 백만원), 건설수주_주택(단위 백만원), 경상수지(백만불), 무역수지(백만불), 대출금액(아파트)(억원), 대출잔액(아파트)(억원), 서울_신규_분양세대(단위: 세대), 경제활동인구_취업자(단위: 천명), 국제 주요국 주가지수(KOSPI), 원화의 대위안/대엔 환율(원/달러(종가)_원\n",
        "\n"
      ],
      "metadata": {
        "id": "ncqo8rJrdbHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# object -> float 형으로 데이터타입 변환\n",
        "transaction_fee = data['거래금액(만원)']\n",
        "CO_architecture = data['건설수주_건축(단위 백만원)']\n",
        "CO_dwellinghouse = data['건설수주_주택(단위 백만원)']\n",
        "current_balance = data['경상수지(백만불)']\n",
        "trade_balance = data['무역수지(백만불)']\n",
        "loan_amount = data['대출금액(아파트)(억원)']\n",
        "loan_balance = data['대출잔액(아파트)(억원)']\n",
        "Newly_Offered_Housing_Units_in_Seoul = data['서울_신규_분양세대(단위: 세대)']\n",
        "employed_person = data['경제활동인구_취업자(단위: 천명)']\n",
        "KOSPI = data['국제 주요국 주가지수(KOSPI)']\n",
        "KRW_to_USD = data['원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원']\n",
        "\n",
        "transaction_fee_comma_removed = transaction_fee.apply(lambda x: x.replace(',', ''))\n",
        "data['거래금액(만원)'] = transaction_fee_comma_removed.astype(float)\n",
        "CO_architecture_comma_removed = CO_architecture.apply(lambda x: x.replace(',', ''))\n",
        "data['건설수주_건축(단위 백만원)'] = CO_architecture_comma_removed.astype(float)\n",
        "CO_dwellinghouse_comma_removed = CO_dwellinghouse.apply(lambda x: x.replace(',', ''))\n",
        "data['건설수주_주택(단위 백만원)'] = CO_dwellinghouse_comma_removed.astype(float)\n",
        "current_balance_comma_removed = current_balance.apply(lambda x: x.replace(',', ''))\n",
        "data['경상수지(백만불)'] = current_balance_comma_removed.astype(float)\n",
        "trade_balance_comma_removed = trade_balance.apply(lambda x: x.replace(',', ''))\n",
        "data['무역수지(백만불)'] = trade_balance_comma_removed.astype(float)\n",
        "loan_amount_comma_removed = loan_amount.apply(lambda x: x.replace(',', ''))\n",
        "data['대출금액(아파트)(억원)'] = loan_amount_comma_removed.astype(float)\n",
        "loan_balance_comma_removed = loan_balance.apply(lambda x: x.replace(',', ''))\n",
        "data['대출잔액(아파트)(억원)'] = loan_balance_comma_removed.astype(float)\n",
        "Newly_Offered_Housing_Units_in_Seoul_comma_removed = Newly_Offered_Housing_Units_in_Seoul.apply(lambda x: x.replace(',', ''))\n",
        "data['서울_신규_분양세대(단위: 세대)'] = Newly_Offered_Housing_Units_in_Seoul_comma_removed.astype(float)\n",
        "employed_person_comma_removed = employed_person.apply(lambda x: x.replace(',', ''))\n",
        "data['경제활동인구_취업자(단위: 천명)'] = employed_person_comma_removed.astype(float)\n",
        "KOSPI_comma_removed = KOSPI.apply(lambda x: x.replace(',', ''))\n",
        "data['국제 주요국 주가지수(KOSPI)'] = KOSPI_comma_removed.astype(float)\n",
        "KRW_to_USD_comma_removed = KRW_to_USD.apply(lambda x: x.replace(',', ''))\n",
        "data['원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원'] = KRW_to_USD_comma_removed.astype(float)\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Luy4hFSTkgu3",
        "outputId": "53fb9e71-69b8-4a32-ec9d-5d848ee00e77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7862 entries, 0 to 7861\n",
            "Data columns (total 34 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   매칭 구                                7862 non-null   object \n",
            " 1   전용면적(㎡)                             7862 non-null   float64\n",
            " 2   계약년월                                7862 non-null   int64  \n",
            " 3   계약일                                 7862 non-null   int64  \n",
            " 4   거래금액(만원)                            7862 non-null   float64\n",
            " 5   층                                   7862 non-null   int64  \n",
            " 6   건축년도                                7862 non-null   int64  \n",
            " 7   건설수주_건축(단위 백만원)                     7862 non-null   float64\n",
            " 8   건설수주_주택(단위 백만원)                     7862 non-null   float64\n",
            " 9   매매가격지수(아파트)                         7862 non-null   float64\n",
            " 10  경상수지(백만불)                           7862 non-null   float64\n",
            " 11  무역수지(백만불)                           7862 non-null   float64\n",
            " 12  대출금액(아파트)(억원)                       7862 non-null   float64\n",
            " 13  대출잔액(아파트)(억원)                       7862 non-null   float64\n",
            " 14  서울_신규_분양세대(단위: 세대)                  7862 non-null   float64\n",
            " 15  아파트 동(호)수_(단위: 호)                   7862 non-null   int64  \n",
            " 16  아파트 건물면적_(천)                        7755 non-null   float64\n",
            " 17  생산자물가지수 총지수                         7862 non-null   float64\n",
            " 18  전규모(1인이상) 전체임금총액[원]                 7862 non-null   int64  \n",
            " 19  소비자물가지수 총지수                         7862 non-null   float64\n",
            " 20  소비자물가지수 주택, 수도, 전기 및 연료             7862 non-null   float64\n",
            " 21  가계대출 (연리%)                          7862 non-null   float64\n",
            " 22  경기종합지수(2020=100)                    7862 non-null   float64\n",
            " 23  경제활동인구_ 실업률(단위: %)                  7862 non-null   float64\n",
            " 24  경제활동인구_고용률(단위: %)                   7862 non-null   float64\n",
            " 25  경제활동인구_취업자(단위: 천명)                  7862 non-null   float64\n",
            " 26  국제 주요국 주가지수(KOSPI)                  7862 non-null   float64\n",
            " 27  예금은행 대출금리(신규취급액 기준)_대출평균(연%)        7862 non-null   float64\n",
            " 28  예금은행 대출금리(잔액 기준)_총대출(연리%)           7862 non-null   float64\n",
            " 29  주택매매가격지수(KB)_서울                     7862 non-null   float64\n",
            " 30  소비자물가지수_총지수(가중치:1000?)              7862 non-null   float64\n",
            " 31  원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원  7862 non-null   float64\n",
            " 32  경기종합지수                              7862 non-null   float64\n",
            " 33  평당가                                 7862 non-null   float64\n",
            "dtypes: float64(27), int64(6), object(1)\n",
            "memory usage: 2.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# 매칭구(object)에 대해 원핫인코딩 적용\n",
        "data_encoded = pd.get_dummies(data, columns=['매칭 구'], drop_first=True)\n",
        "\n",
        "# 결과 출력\n",
        "print(data_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-0EbwJzeqx2",
        "outputId": "decdcbde-a176-41ea-d01f-c8ce8e50b225"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      전용면적(㎡)    계약년월  계약일  거래금액(만원)   층  건축년도  건설수주_건축(단위 백만원)  \\\n",
            "0       74.66  202101   17  245000.0   7  2020       10589107.0   \n",
            "1       59.92  202105   22  198500.0  18  2020       11699841.0   \n",
            "2       49.92  202105   22  180000.0   7  2020       11699841.0   \n",
            "3       59.92  202105   22  198500.0  18  2020       11699841.0   \n",
            "4       49.92  202105   22  180000.0   7  2020       11699841.0   \n",
            "...       ...     ...  ...       ...  ..   ...              ...   \n",
            "7857    59.74  202011   28  104000.0   5  2011       13510590.0   \n",
            "7858    59.74  202012    1  102000.0   5  2011       22231493.0   \n",
            "7859    59.74  202012    5  106000.0  13  2011       22231493.0   \n",
            "7860    84.98  202012   10  128000.0   2  2011       22231493.0   \n",
            "7861    84.97  202012   16  126500.0  10  2011       22231493.0   \n",
            "\n",
            "      건설수주_주택(단위 백만원)  매매가격지수(아파트)  경상수지(백만불)  ...  매칭 구_마포구  매칭 구_서대문구  \\\n",
            "0           6436523.0         97.0     5762.0  ...         0          0   \n",
            "1           5568538.0         99.0    11307.0  ...         0          0   \n",
            "2           5568538.0         99.0    11307.0  ...         0          0   \n",
            "3           5568538.0         99.0    11307.0  ...         0          0   \n",
            "4           5568538.0         99.0    11307.0  ...         0          0   \n",
            "...               ...          ...        ...  ...       ...        ...   \n",
            "7857        8663124.0         96.4     9619.0  ...         0          0   \n",
            "7858       15138239.0         96.6    12063.0  ...         0          0   \n",
            "7859       15138239.0         96.6    12063.0  ...         0          0   \n",
            "7860       15138239.0         96.6    12063.0  ...         0          0   \n",
            "7861       15138239.0         96.6    12063.0  ...         0          0   \n",
            "\n",
            "      매칭 구_서초구  매칭 구_성동구  매칭 구_성북구  매칭 구_송파구  매칭 구_영등포구  매칭 구_용산구  매칭 구_은평구  \\\n",
            "0            0         0         0         0          0         0         0   \n",
            "1            0         0         0         0          0         0         0   \n",
            "2            0         0         0         0          0         0         0   \n",
            "3            0         0         0         0          0         0         0   \n",
            "4            0         0         0         0          0         0         0   \n",
            "...        ...       ...       ...       ...        ...       ...       ...   \n",
            "7857         0         0         0         0          0         0         0   \n",
            "7858         0         0         0         0          0         0         0   \n",
            "7859         0         0         0         0          0         0         0   \n",
            "7860         0         0         0         0          0         0         0   \n",
            "7861         0         0         0         0          0         0         0   \n",
            "\n",
            "      매칭 구_중구  \n",
            "0           0  \n",
            "1           0  \n",
            "2           0  \n",
            "3           0  \n",
            "4           0  \n",
            "...       ...  \n",
            "7857        1  \n",
            "7858        1  \n",
            "7859        1  \n",
            "7860        1  \n",
            "7861        1  \n",
            "\n",
            "[7862 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-2. 결측치 확인**"
      ],
      "metadata": {
        "id": "Ezs30u4mh1s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_encoded"
      ],
      "metadata": {
        "id": "WDCHqv7KjGtL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isnull().sum()\n",
        "\n",
        "# 결과 출력\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O_05VuRjDVD",
        "outputId": "5d4dfdee-280f-490a-a472-36ed9ffb6ea9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전용면적(㎡)                                 0\n",
            "계약년월                                    0\n",
            "계약일                                     0\n",
            "거래금액(만원)                                0\n",
            "층                                       0\n",
            "건축년도                                    0\n",
            "건설수주_건축(단위 백만원)                         0\n",
            "건설수주_주택(단위 백만원)                         0\n",
            "매매가격지수(아파트)                             0\n",
            "경상수지(백만불)                               0\n",
            "무역수지(백만불)                               0\n",
            "대출금액(아파트)(억원)                           0\n",
            "대출잔액(아파트)(억원)                           0\n",
            "서울_신규_분양세대(단위: 세대)                      0\n",
            "아파트 동(호)수_(단위: 호)                       0\n",
            "아파트 건물면적_(천)                          107\n",
            "생산자물가지수 총지수                             0\n",
            "전규모(1인이상) 전체임금총액[원]                     0\n",
            "소비자물가지수 총지수                             0\n",
            "소비자물가지수 주택, 수도, 전기 및 연료                 0\n",
            "가계대출 (연리%)                              0\n",
            "경기종합지수(2020=100)                        0\n",
            "경제활동인구_ 실업률(단위: %)                      0\n",
            "경제활동인구_고용률(단위: %)                       0\n",
            "경제활동인구_취업자(단위: 천명)                      0\n",
            "국제 주요국 주가지수(KOSPI)                      0\n",
            "예금은행 대출금리(신규취급액 기준)_대출평균(연%)            0\n",
            "예금은행 대출금리(잔액 기준)_총대출(연리%)               0\n",
            "주택매매가격지수(KB)_서울                         0\n",
            "소비자물가지수_총지수(가중치:1000?)                  0\n",
            "원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원      0\n",
            "경기종합지수                                  0\n",
            "평당가                                     0\n",
            "매칭 구_강동구                                0\n",
            "매칭 구_강북구                                0\n",
            "매칭 구_광진구                                0\n",
            "매칭 구_구로구                                0\n",
            "매칭 구_노원구                                0\n",
            "매칭 구_동대문구                               0\n",
            "매칭 구_동작구                                0\n",
            "매칭 구_마포구                                0\n",
            "매칭 구_서대문구                               0\n",
            "매칭 구_서초구                                0\n",
            "매칭 구_성동구                                0\n",
            "매칭 구_성북구                                0\n",
            "매칭 구_송파구                                0\n",
            "매칭 구_영등포구                               0\n",
            "매칭 구_용산구                                0\n",
            "매칭 구_은평구                                0\n",
            "매칭 구_중구                                 0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-3. 이상치 제거**"
      ],
      "metadata": {
        "id": "74DFlA2mh4WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 이상치 확인\n",
        "Q1 = df['평당가'].quantile(0.25)\n",
        "Q3 = df['평당가'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# IQR을 사용하여 이상치 식별\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = (df['평당가'] < lower_bound) | (df['평당가'] > upper_bound)\n",
        "\n",
        "# 이상치를 제외한 데이터프레임 생성\n",
        "filtered_df = df[~outliers]\n",
        "\n",
        "# 결과 출력\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG4q3uDvmVnm",
        "outputId": "fccf021a-4b6a-4908-c0e7-362cd3beb542"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      전용면적(㎡)    계약년월  계약일  거래금액(만원)   층  건축년도  건설수주_건축(단위 백만원)  \\\n",
            "26     84.943  202102   15  251000.0   1  2019       10479357.0   \n",
            "71    110.390  202104   30  285000.0  10  1989       14183240.0   \n",
            "72    110.390  202105   26  300000.0  13  1989       11699841.0   \n",
            "73    110.390  202108   10  300000.0  16  1989       13557522.0   \n",
            "74    106.390  202103    5  280000.0  13  2016       13259062.0   \n",
            "...       ...     ...  ...       ...  ..   ...              ...   \n",
            "7857   59.740  202011   28  104000.0   5  2011       13510590.0   \n",
            "7858   59.740  202012    1  102000.0   5  2011       22231493.0   \n",
            "7859   59.740  202012    5  106000.0  13  2011       22231493.0   \n",
            "7860   84.980  202012   10  128000.0   2  2011       22231493.0   \n",
            "7861   84.970  202012   16  126500.0  10  2011       22231493.0   \n",
            "\n",
            "      건설수주_주택(단위 백만원)  매매가격지수(아파트)  경상수지(백만불)  ...  매칭 구_마포구  매칭 구_서대문구  \\\n",
            "26          5379397.0         97.7     6520.0  ...         0          0   \n",
            "71          8377800.0         98.6      518.0  ...         0          0   \n",
            "72          5568538.0         99.0    11307.0  ...         0          0   \n",
            "73          6564711.0        101.7     6701.0  ...         0          0   \n",
            "74          6936574.0         98.1     6689.0  ...         0          0   \n",
            "...               ...          ...        ...  ...       ...        ...   \n",
            "7857        8663124.0         96.4     9619.0  ...         0          0   \n",
            "7858       15138239.0         96.6    12063.0  ...         0          0   \n",
            "7859       15138239.0         96.6    12063.0  ...         0          0   \n",
            "7860       15138239.0         96.6    12063.0  ...         0          0   \n",
            "7861       15138239.0         96.6    12063.0  ...         0          0   \n",
            "\n",
            "      매칭 구_서초구  매칭 구_성동구  매칭 구_성북구  매칭 구_송파구  매칭 구_영등포구  매칭 구_용산구  매칭 구_은평구  \\\n",
            "26           0         0         0         0          0         0         0   \n",
            "71           0         0         0         0          0         0         0   \n",
            "72           0         0         0         0          0         0         0   \n",
            "73           0         0         0         0          0         0         0   \n",
            "74           0         0         0         0          0         0         0   \n",
            "...        ...       ...       ...       ...        ...       ...       ...   \n",
            "7857         0         0         0         0          0         0         0   \n",
            "7858         0         0         0         0          0         0         0   \n",
            "7859         0         0         0         0          0         0         0   \n",
            "7860         0         0         0         0          0         0         0   \n",
            "7861         0         0         0         0          0         0         0   \n",
            "\n",
            "      매칭 구_중구  \n",
            "26          0  \n",
            "71          0  \n",
            "72          0  \n",
            "73          0  \n",
            "74          0  \n",
            "...       ...  \n",
            "7857        1  \n",
            "7858        1  \n",
            "7859        1  \n",
            "7860        1  \n",
            "7861        1  \n",
            "\n",
            "[7417 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = filtered_df"
      ],
      "metadata": {
        "id": "LY5FbwsPnpd0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-4. 스케일링**\n",
        "\n",
        "- min-max scaling 진행 (매칭구 / 타겟변수 제외한 모든 column들에 대해서)"
      ],
      "metadata": {
        "id": "jrjNA5TFmWUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = data.columns\n",
        "print(column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcncBX3smiBY",
        "outputId": "ed514d2b-676e-4d2b-c9c5-f0bc4c11c7a9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['전용면적(㎡)', '계약년월', '계약일', '거래금액(만원)', '층', '건축년도', '건설수주_건축(단위 백만원)',\n",
            "       '건설수주_주택(단위 백만원)', '매매가격지수(아파트)', '경상수지(백만불)', '무역수지(백만불)',\n",
            "       '대출금액(아파트)(억원)', '대출잔액(아파트)(억원)', '서울_신규_분양세대(단위: 세대)',\n",
            "       '아파트 동(호)수_(단위: 호)', '아파트 건물면적_(천)', '생산자물가지수 총지수 ',\n",
            "       '전규모(1인이상) 전체임금총액[원]', '소비자물가지수 총지수 ', '소비자물가지수 주택, 수도, 전기 및 연료',\n",
            "       '가계대출 (연리%)', '경기종합지수(2020=100)', '경제활동인구_ 실업률(단위: %)',\n",
            "       '경제활동인구_고용률(단위: %)', '경제활동인구_취업자(단위: 천명)', '국제 주요국 주가지수(KOSPI)',\n",
            "       '예금은행 대출금리(신규취급액 기준)_대출평균(연%)', '예금은행 대출금리(잔액 기준)_총대출(연리%)',\n",
            "       '주택매매가격지수(KB)_서울', '소비자물가지수_총지수(가중치:1000?)',\n",
            "       '원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원', '경기종합지수', '평당가', '매칭 구_강동구',\n",
            "       '매칭 구_강북구', '매칭 구_광진구', '매칭 구_구로구', '매칭 구_노원구', '매칭 구_동대문구', '매칭 구_동작구',\n",
            "       '매칭 구_마포구', '매칭 구_서대문구', '매칭 구_서초구', '매칭 구_성동구', '매칭 구_성북구', '매칭 구_송파구',\n",
            "       '매칭 구_영등포구', '매칭 구_용산구', '매칭 구_은평구', '매칭 구_중구'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# 연속형 변수 선택\n",
        "continuous_columns = ['전용면적(㎡)', '계약년월', '계약일', '거래금액(만원)', '층', '건축년도', '건설수주_건축(단위 백만원)',\n",
        "       '건설수주_주택(단위 백만원)', '매매가격지수(아파트)', '경상수지(백만불)', '무역수지(백만불)',\n",
        "       '대출금액(아파트)(억원)', '대출잔액(아파트)(억원)', '서울_신규_분양세대(단위: 세대)',\n",
        "       '아파트 동(호)수_(단위: 호)', '아파트 건물면적_(천)', '생산자물가지수 총지수 ',\n",
        "       '전규모(1인이상) 전체임금총액[원]', '소비자물가지수 총지수 ', '소비자물가지수 주택, 수도, 전기 및 연료',\n",
        "       '가계대출 (연리%)', '경기종합지수(2020=100)', '경제활동인구_ 실업률(단위: %)',\n",
        "       '경제활동인구_고용률(단위: %)', '경제활동인구_취업자(단위: 천명)', '국제 주요국 주가지수(KOSPI)',\n",
        "       '예금은행 대출금리(신규취급액 기준)_대출평균(연%)', '예금은행 대출금리(잔액 기준)_총대출(연리%)',\n",
        "       '주택매매가격지수(KB)_서울', '소비자물가지수_총지수(가중치:1000?)',\n",
        "       '원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원', '경기종합지수']\n",
        "\n",
        "# 숫자열에 있는 쉼표(,) 제거하고 숫자로 변환\n",
        "df[continuous_columns] = df[continuous_columns].replace({',': ''}, regex=True).astype(float)\n",
        "\n",
        "# 연속형 변수에 대해 Min-Max Scaling 적용\n",
        "scaler = MinMaxScaler()\n",
        "df[continuous_columns] = scaler.fit_transform(df[continuous_columns])\n",
        "\n",
        "# 결과 출력\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqfXfl0WoyvY",
        "outputId": "7f781d0a-31ee-4622-8a37-ff7b0521e4c6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       전용면적(㎡)      계약년월       계약일  거래금액(만원)         층      건축년도  \\\n",
            "0     0.220526  0.473934  0.533333  0.262884  0.133333  0.977273   \n",
            "1     0.142947  0.492891  0.700000  0.205278  0.377778  0.977273   \n",
            "2     0.090316  0.492891  0.700000  0.182359  0.133333  0.977273   \n",
            "3     0.142947  0.492891  0.700000  0.205278  0.377778  0.977273   \n",
            "4     0.090316  0.492891  0.700000  0.182359  0.133333  0.977273   \n",
            "...        ...       ...       ...       ...       ...       ...   \n",
            "7857  0.142000  0.047393  0.900000  0.088206  0.088889  0.772727   \n",
            "7858  0.142000  0.052133  0.000000  0.085728  0.088889  0.772727   \n",
            "7859  0.142000  0.052133  0.133333  0.090684  0.266667  0.772727   \n",
            "7860  0.274842  0.052133  0.300000  0.117939  0.022222  0.772727   \n",
            "7861  0.274789  0.052133  0.500000  0.116080  0.200000  0.772727   \n",
            "\n",
            "      건설수주_건축(단위 백만원)  건설수주_주택(단위 백만원)  매매가격지수(아파트)  경상수지(백만불)  ...  매칭 구_마포구  \\\n",
            "0            0.240076         0.223136     0.281553   0.608317  ...         0   \n",
            "1            0.312576         0.145645     0.475728   0.953006  ...         0   \n",
            "2            0.312576         0.145645     0.475728   0.953006  ...         0   \n",
            "3            0.312576         0.145645     0.475728   0.953006  ...         0   \n",
            "4            0.312576         0.145645     0.475728   0.953006  ...         0   \n",
            "...               ...              ...          ...        ...  ...       ...   \n",
            "7857         0.430768         0.421921     0.223301   0.848076  ...         0   \n",
            "7858         1.000000         1.000000     0.242718   1.000000  ...         0   \n",
            "7859         1.000000         1.000000     0.242718   1.000000  ...         0   \n",
            "7860         1.000000         1.000000     0.242718   1.000000  ...         0   \n",
            "7861         1.000000         1.000000     0.242718   1.000000  ...         0   \n",
            "\n",
            "      매칭 구_서대문구  매칭 구_서초구  매칭 구_성동구  매칭 구_성북구  매칭 구_송파구  매칭 구_영등포구  매칭 구_용산구  \\\n",
            "0             0         0         0         0         0          0         0   \n",
            "1             0         0         0         0         0          0         0   \n",
            "2             0         0         0         0         0          0         0   \n",
            "3             0         0         0         0         0          0         0   \n",
            "4             0         0         0         0         0          0         0   \n",
            "...         ...       ...       ...       ...       ...        ...       ...   \n",
            "7857          0         0         0         0         0          0         0   \n",
            "7858          0         0         0         0         0          0         0   \n",
            "7859          0         0         0         0         0          0         0   \n",
            "7860          0         0         0         0         0          0         0   \n",
            "7861          0         0         0         0         0          0         0   \n",
            "\n",
            "      매칭 구_은평구  매칭 구_중구  \n",
            "0            0        0  \n",
            "1            0        0  \n",
            "2            0        0  \n",
            "3            0        0  \n",
            "4            0        0  \n",
            "...        ...      ...  \n",
            "7857         0        1  \n",
            "7858         0        1  \n",
            "7859         0        1  \n",
            "7860         0        1  \n",
            "7861         0        1  \n",
            "\n",
            "[7862 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-5. vif 전 변수 걸러내기**"
      ],
      "metadata": {
        "id": "elERNN15pWZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-6. 타겟변수 (평당가) 분석**"
      ],
      "metadata": {
        "id": "fXAcS60MpCYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 평당가 열 선택\n",
        "price_per_area = df['평당가']\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.plot(price_per_area)\n",
        "plt.title('평당가 변화')\n",
        "plt.xlabel('데이터 포인트')\n",
        "plt.ylabel('평당가')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "C0iH4AttpIE9",
        "outputId": "5b68e55f-0b3f-4709-9169-ae5347cd65d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54217 (\\N{HANGUL SYLLABLE PYEONG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 45817 (\\N{HANGUL SYLLABLE DANG}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 48320 (\\N{HANGUL SYLLABLE BYEON}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54868 (\\N{HANGUL SYLLABLE HWA}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 45936 (\\N{HANGUL SYLLABLE DE}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 53552 (\\N{HANGUL SYLLABLE TEO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 51064 (\\N{HANGUL SYLLABLE IN}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "로그 변환시켜서 타겟 변수 또한 정규분포에 가깝게 만들어준다."
      ],
      "metadata": {
        "id": "43bEdr9BpcpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 로그 변환\n",
        "log_price_per_area = np.log1p(price_per_area)\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.plot(log_price_per_area)\n",
        "plt.title('로그 변환된 평당가 변화')\n",
        "plt.xlabel('데이터 포인트')\n",
        "plt.ylabel('로그 변환된 평당가')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vc25MmKNpcTU",
        "outputId": "315d4d6d-8dea-4bcc-c57b-1468690b3070"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 54872 (\\N{HANGUL SYLLABLE HWAN}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 46108 (\\N{HANGUL SYLLABLE DOEN}) missing from current font.\n",
            "  fig.canvas.print_figure(bytes_io, **kw)\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Malgun Gothic' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6VElEQVR4nO3dd3wUZf4H8M+mJ4QUShoJJHQInVASQEBRQCx4HoqHCqKeKCqoPxDsyim2U+zoIaCictiQA0HpSA0gvXcChE4agdT5/QG7bJnZ6TPPzH7f9/J1ZHfKM7Mzz3znqQ6O4zgQQgghhNhQkNkJIIQQQgjRCwU6hBBCCLEtCnQIIYQQYlsU6BBCCCHEtijQIYQQQohtUaBDCCGEENuiQIcQQgghtkWBDiGEEEJsiwIdQgghhNgWBTqEEEIIsS0KdAghhBBiWxToEBIgduzYgbCwMERHR/P+FxYWhgMHDkheTkhSUpLguhEREZg6daouy/G5++67ERUVxbtuVFQUhg4dqstyfD799FNEREQIHkt6erqs5Qgh0lCgQ0iA4DgOnTt3RklJCe9/HTp0AMdxkpcTUllZiYKCAt51R48ejerqal2W41NVVYU5c+bwrvvzzz+jqqpKl+X4VFdX4//+7/941z179iwqKytlLUcIkYYCHUIIIYTYFgU6hBBCCLEtCnQIIYQQYlsU6BBCCCHEtijQIYQQQohtUaBDCCGEENuiQIcQQgghtkWBDiGEEEJsiwIdQgghhNgWBTqEEEIIsS0KdAghhBBiWxToEEIIIcS2QsxOACHEOGvXrkVcXBzvdyUlJbKXE1KnTh3ezy9fvoyPP/5Yt+X4DBw4ECEhvlldZWUlBg4cqNtyfN59913B9EZHR8tejhAizsH5m4aYEEIIIcTCqOqKEEIIIbZFgQ4hhBBCbIsCHUIIIYTYVsA1Rq6ursaJEydQs2ZNOBwOs5NDCCGEEAk4jkNxcTFSUlIQFCS9nCbgAp0TJ04gLS3N7GQQQgghRIG8vDykpqZKXj7gAp2aNWsCuHKiYmJiTE4NIYQQQqQoKipCWlqa6zkuVcAFOs7qqpiYGAp0CCGEEIuR2+yEGiMTQgghxLYo0CGEEEKIbVGgQwghhBDbokCHEEIIIbZFgQ4hhBBCbIsCHUIIIYTYFgU6hBBCCLEtCnQIIYQQYlsU6BBCCCHEtijQIYQQQohtUaBDCCGEENuiQIcQQgghtmVqoFNVVYUXX3wRGRkZiIyMRKNGjTBhwgRwHCe4zrJly+BwOHz+O3nypIEpJ2pdKq8yOwmEEEICgKmzl7/11lv47LPP8NVXXyEzMxMbNmzAAw88gNjYWDz55JN+192zZ4/H7OMJCQl6J5do5INF+/D+or34anhn9Gxa1+zkEEIIsTFTA53Vq1fj9ttvx4ABAwAA6enp+P7775Gbmyu6bkJCAuLi4nROIdHD+4v2AgBemL0Nf4693uTUEEIIsTNTq65ycnKwePFi7N175cG3ZcsWrFy5Ev379xddt127dkhOTsaNN96IVatW6Z1UQgghhFiQqSU648aNQ1FREZo3b47g4GBUVVXh9ddfx5AhQwTXSU5OxuTJk5GVlYWysjJMmTIFvXr1wrp169ChQwef5cvKylBWVub6u6ioSJdjIYQQQgh7TA10Zs2ahW+//RbfffcdMjMzsXnzZowePRopKSkYOnQo7zrNmjVDs2bNXH/n5OTgwIEDeP/99/HNN9/4LD9x4kS8+uqruh0DIYQQQthlatXVmDFjMG7cOAwePBitW7fGfffdh6eeegoTJ06UtZ3OnTtj//79vN+NHz8ehYWFrv/y8vK0SDrRgJ/OdYQQQogmTC3RKS0tRVCQZ6wVHByM6upqWdvZvHkzkpOTeb8LDw9HeHi44jQSQgghxLpMDXRuvfVWvP7666hfvz4yMzOxadMmvPfeexg+fLhrmfHjx+P48eP4+uuvAQCTJk1CRkYGMjMzcfnyZUyZMgVLlizBH3/8YdZhEIWoRIcQQojeTA10PvroI7z44ot47LHHcPr0aaSkpOCRRx7BSy+95FomPz8fR48edf1dXl6OZ555BsePH0dUVBTatGmDRYsWoXfv3mYcAiGEEEIY5uD8DUNsQ0VFRYiNjUVhYaHHgIPEOOnj5gEA6sVFYtU4GkeHEEKIOKXPb5rrihBCCCG2RYEOIYQQQmyLAh1iqO3HC13/DrBaU81tPHIeY37YgnMlZeILE0JIgDK1MTIJPLd8tNLsJNjGnZ+tAQBcqqjCx//wHRWcEEIIlegQE1F5jjYOnb1odhIIIYRZFOgQYnE7TtD8bYQQIoQCHZ1VV3PYc7IY1dVUfuEtv/Cy2UmwrMnLD5idBEIIsQQKdHT21oLd6DtpBd5csNvspBAbeXM+XU+EECIFBTo6+3zFQQDAF1f/nxBCCCHGoUCHEEIIIbZFgQ4xzOWKKrOTYJqSskr8ti0fpeWVZieFEEICCgU6xDAfL9lvdhJM88R3f+Gxb//CuJ+2mZ0UQggJKBTo6KSssgr3fLHW7GQwZcOR82YnwRRFlyuwdM8ZAMCcLSdMTg0hhAQWCnR08uvmE1hz8JzZyWBKoM748PR/t5idBEIICVgU6OikLIDbowgJ0DgHi3adMjsJhBASsCjQ0QmND+irrLLa7CQQQggJMBTo6IRm5vZ0qbwKW/IKzE6Gbd0/NRdDp+Yquu6qqjk8MC0X7/xOgxASQuyHAh2dlJRRN2J3244Xmp0EW1ux9wyW7z2DgtIKResu3XMGnyylaSUIIfZDgY5O3v1jr9lJIITX5rwCdHljkasHGFUpEkLsjAIdQgLMI99swKmiMjz5/Sazk0KIX/tPF6P3u8vw81/HzE4KsTAKdAixkcPnLoouU1FF7ccIu/LOl2LW+jxUVlXjmVlbcOjsRTw9i4ZoIMqFmJ0AEhgcDrNTEBhemL0d857sYXYyCFGsx9tLAVwZaPPo+VKTU0PsgAIdQmyktFx8/CaKOYkV/GveLrOTQGyCqq4IsZEqCQM4UcUVISSQUKBDDEGlCMaQEugQQkggoUCHEBuRMmAgBZ2EkEBCgQ4hAY4aihNC7IwaI5uA4zg4AuzpEmCHSwiRqbqakzQ8AiFyUaCjgx825Al+98+vN+BUcRl+fjQHwUH09CeEEOBKL6upqw6ZnQxiQ1R1pYMxP271+axB7SgAwB87T2FLXgF2nigyOlmEiMqjcUuISSjIIXqhQMckVJVDzOLv2nv46w3GJYQQQgxAgY6GKquqMfCTVbzfUVzDfwZyD503OB3En90ni81OAiGEaIoCHQ1tPHIBm/MKeL9zOBySuv4Gmrs+X2N2EmzlROFl2etQEE4IsTMKdDT0hMhs0O5xDlVdEVa4B+d0XRJC7IYCHQ2dLi4T/M4Bz6H3HQH2Hi33AVpRVY2Kqmp9EkM8fLrsgOvfgXVVEkICAQU6RnFIG7WWXJnGIHviYuS8uYSmNDAYnW5CiN1QoGMgjxIdenV24TgOFy6Wu/4+V1KGsyXlOFNchqJLFSamTD02g1u6+AghgYMCHY0UijyQD565iK9WH3b9TYHONeN/3ob2ExZi+d4zPt8t2nXKhBRpZ8qf1hsbhM3gjBBClKFARyMHz5SILvOvebtc/w60Njr+zFx/ZSTpSYv2+nw35setOGLhYeE/X3FAfCHG/G9rvtlJIIQQzVCgY5JAK9FRc7gnCuR3mSbK/clTskYIIVZFgY5GqLDfPymTmG46WsBbbWLtKcGsl3hqAE4IsRMKdDQit1mD9R5/6kgNVhbvOu3zmZVnej9bIjzkAAv4AstKCnQIITZCgY5m5D0cLPzsViRI4gGfu+gbGFipRGdzXgFembPDb+N0lhr7llX6jlXETuoIIUQ9CnQ0Ivcl+I5PViO/8JI+iWFQsMRoxQGHT3GXlUp0Bn6yCtNXH8ab83cJLvPynB0Gpkg+65xtQggRR4GORuS+pBeXVeK1/+3UJzEMklqiA8CnSMFCcY7LvlPCvfC+XnPEwJT4suL5JIQQpSjQ0YiS6oiSskodUsImydVPPMvJCpIIIYQQNxToaITaNWhj0sK9vlVX5iRFFbHr4diFUlXbT42PVLW+XBzHYerKQ1hz4Jyh+yWEELUo0NEIQ+1LLe1Eoe+YOVLb97Bk45ELfr/PPXRe1fZTYvULdPgK0JbvPYPX5u7EPf9Zq9t+CSFEDxToaISjMh2/1JwdqrrST/MXF/B+frr4Mh6dsREr950FABw9r64EihBCzEKBjkaUPIyt1JvITFYs0dGbmsBa7Gw6ALw+bxfmbz+Je79cp3g/hGjp183HzU4CsSgKdDQSHR5idhKYpqZqj+IcbUn5Kc4Usz3QIQk8o2Zuxqr9Z81OBrEgCnQ0cqmiyuwk2FZIsP0uU5YL8xwOh0f6ft18HC/9yvbYPyQw7DlZbHYSiAXZ7wlikuZJNc1OAiEIDRaPoOTGWKNmblaUFkK0FiLh+ibEGwU6GqkZEWp2Epgmq00JtesWJVQV2L1xHdXbpkcJYZXUtpDVNF8bcUOBDmEeS3NDEULMI6Vjwv1Tc9Hwud8Caood4h8FOhpaMLqH2UmwBQprlNPk3FGRDmFUsIQSnRV7zwAAsicu0Ts5xCIo0NFQ86QYs5PALDmFMlSAQwjhQ0NNECUo0DER3bLSUNzjS+icSAkSxV6KHVf/RwhrOADv/bEH6w7yT0VyqZx6vxJfFOjopF6csXMRsU5WiQ6FNqZiues7CWw/bMjDh0v24+4v+KciWbrntMEpIlZAo9wR5lDVlbn2ny5BCFUREAbliUxF8tu2fINSQqyEAh3CPCsHPvVrRRk6T1StGmGqt7E5r0B9QgjRQbCfcXTyCy9h7lYKdIgvU6uuqqqq8OKLLyIjIwORkZFo1KgRJkyYINqdeNmyZejQoQPCw8PRuHFjTJ8+3ZgEE8XkVEdZOK7x0bBuDV22K3SPJMVG6LI/QlgQEiT8yHrjt90GpoRYiaklOm+99RY+++wzfPXVV8jMzMSGDRvwwAMPIDY2Fk8++STvOocOHcKAAQMwYsQIfPvtt1i8eDEeeughJCcno2/fvgYfgTBq56CcncbNMfoysNGpI8SHvyrVMpqGhwgwNdBZvXo1br/9dgwYMAAAkJ6eju+//x65ubmC60yePBkZGRn497//DQBo0aIFVq5ciffff5+pQId4UvcApqe3lqhHFbEq9+7lny07gM4ZtdCxQbyJKSJWYGrVVU5ODhYvXoy9e/cCALZs2YKVK1eif//+guusWbMGffr08fisb9++WLNmDe/yZWVlKCoq8viPsI2FUonS8kq8vWA3tujUXkVtsCHYvVxCUEi92ohVRYQGu/791oLduPOz1SamhliFqYHOuHHjMHjwYDRv3hyhoaFo3749Ro8ejSFDhgiuc/LkSSQmJnp8lpiYiKKiIly65Dvk98SJExEbG+v6Ly0tTfPjIMb4c98Z3PflOtGeF1r4cPF+fLrsAG7/ZJXkdQpKy30+c1AdJiGaCQuR/shqlxanX0ICFMdx2JxXgNLySrOTIoupgc6sWbPw7bff4rvvvsNff/2Fr776Cu+++y6++uorzfYxfvx4FBYWuv7Ly8vTbNt8bm6dBAD453UNRZelZ6A0zhKe+77MxZ/7zuKZWVt03+fK/Wdc/y6rlFb3z0SVkJQBA1lIJyEKyLly/9ahnm7pCFQ/bjyGgZ+swqDJ/DUorDK1jc6YMWNcpToA0Lp1axw5cgQTJ07E0KFDeddJSkrCqVOnPD47deoUYmJiEBnpO0hfeHg4wsPDtU+8gE/+0QHnL5bjAs/bPZFGrOrqdPFl3dNQVlHt+rfUqjS+DiGGN0Y2eH+EsGLPqWKPvymc195Pfx0DAOw4Ya0mIKaW6JSWliLI6+kQHByM6upqgTWA7OxsLF682OOzhQsXIjs7W5c0yuVwOFA72rjAyo5YaEOiJAVGppqFdkyEsKSUpn/QnVXzHVMDnVtvvRWvv/465s2bh8OHD+OXX37Be++9hzvuuMO1zPjx43H//fe7/h4xYgQOHjyIsWPHYvfu3fj0008xa9YsPPXUU2YcApFIzQ1ixr2lpIs7C5mAnbrmE+KNrm6ihKlVVx999BFefPFFPPbYYzh9+jRSUlLwyCOP4KWXXnItk5+fj6NHj7r+zsjIwLx58/DUU0/hgw8+QGpqKqZMmUJdyxnBcZzqBrhiz2pmG/gykAtTnENszc/1zWiuQBhgaqBTs2ZNTJo0CZMmTRJchm/U4169emHTpk36JUwTgXHbvfTrduQeOo/ZI7vhTHEZ7vp8DR7snoGHeng2xg6EkZFZqHKTgtU4kRAxfPfYrvwitEiOMSE1gccaOZwvmr3cRHZ43ny95gh2nyzG/O35eH3eLuQXXsa/5u3SdB9ml1JI3T/fcqnx/LPYqw02hMfRISSw9P/gTwAUwBNhFOgQTVRVA5XV2jxmX9c4UFLiTHGZ7HX4jj4hhuaeIkQr/l46aNgEIoQCHaKJao7z+0Ylp1Rm0a5TPp8Z3ci26PK1AbGkVkmx0BCYgSQQYgqrVB1bmkVPMQU6RJHiyxW4+3O3QaM4/ariOHB4+OuNrr9ZnSiThTxASWbfs2ldJNOs58QC/F3dVKKjP6sGkxTo6MTu9cX/WXEQ6w6dd/1drVFRQr04/jYtfKU8RpF6ZIaWpqjYmfel6XDYo70YsT8WSk0D2frDF8xOgiIU6OjE7jdkSZnn4Fwc/LfRkXo2miRGK0+UyVh425Fy2Xkv4gDDXfYJkcj7Ejb/biSsoEBHJ/mF4tMU2Onh4gCwZPdpTbbjzeyYUXLQykDOOn31YVTJbBRup+uQBK6QYLqOCT8KdIgil70muhR7VkoNFvgeutuOFXr8XVYpPEWIHhiIX2QRm92dHgfEjkKD6XFG+Jk6YKCd2blh3CPfbMDvOzzbzOh5vJ+vOODxd2l5pcCS+mCxQMffvuSmw75XKrEbv9e21d5ILKakzNh8V0sUAhNZLldU+QQ5APDj1Vlt1eJ76B44c9Hj73KDS3Sk0qpBtlpy24dRzRWxCkZusYA0f1u+2UlQjAIdnbDy0NPa+wv38n6e69YDi4/UsyHloavRuISCZqw94vmBxP3JbRujF7mp6N8qWZd0EKI1LUsy7eByRRVu/3gl3vhN/0FWjW4yoCUKdHRi10Bn9YFzOu9BPNLRs3fT6eLLeGH2dkX7c//JnXPvaNX7btuxQoyeuQnHCy7JSoeYnk3r4m8d6qlIGSFssHtPVz6/bcvHlmOF+GLFQd33ZeWzS210dGLXe05pNYfU8yFl+3qe24te3ebl7E/PEp1bP14JADh0rhS/juwmkib/6XBv8J3dqDYcDgdVXxFr8HPh2zTL9UuraXekqGakxFoJKtHRScO6NcxOgiVJed6yerut2HdG933syi8SXcauQTYx1+miy5i/LR+VVWxWYQTidR9k4BtKkIVfhijQ0UmD2tYNdI4XXML17y7DV6sP+3yn97Uu6b41OEOTurvI0GBd0wFA0kMmAPN7YoAb31+BR7/9C1+vOSK+sE78t9EJvCvfyOCjUYJ1B3OlQEdHDev4D3ZYDZAn/rYLB89exMtzdmi4VYnj6JjcRkdNPb97RmBme4FAfLMl2iopq8RFr+7EhZcqAABL96gfGFQPgXjdG1miY2XURkdHVRa98/y1rte7mrayWrzEwgpVxXpNkuk8dn/BnpKG8JRhEqfyymq0evl3AMCBN25GsFexAWvXyl1ZqQB8Ax2LZr+yTJyvf28rO6ASHR3JeeCsPnAWu/KL8NPGY77dm010wquXz7bjhQJLauOoyKi+ALu9K9yT1aperMd3rerFCC6rZzrcXbhYjgqvqi/nI0vOs4vV80+0cbakzPXvSxW+jfPNjHP4Lr0a4YH7vn6qqEx8Ia1Y+LYP3CvEABIKJwBcGbL/H/9Z5/HZTS0TkRCjT6nAvlPF+GrNYTzeuwmSREoect5cgjF9m2Fk78aq9im515Wkqiv2OY9X6LjFqt8mLdqL9No10LNpXQRrMIfPsQul6P7WUsHqVDmxC8fRIIN2VFlVjQulFTh/sdznO/fg1swBO/3dNxSAEyEU6OhI6o136OxFn89Ky33fpLRyy0crUVZZjV35xfjp0RzR5d/5fQ+yG9VGh/rxuqXJac+pYt33YQSxQMbfpfHX0QuYtGif4vX59r1o55XRrA+evYh6cZGS1hHePrGjOyevwZa8At7v3Lsxe5fyGsnfdR8dEQLoW+Ac0Kx831PVlY6kXhh8y+n5xuxsg7NdoBqKLzOZvuqwqn1a+SbR403R30zv50t836j1Jq9Ex8q/JhHCF+TMzD2K4dPXY8/Jay8grM52P6hjmqTljl0oxfsL9+JciYHVPjZg5dueAh0dpYt0MXfmF3wPDjtPCgoAOY1qm50EHVz7HcUaRs7dmo/1h/1Pm6E4FTwZktDDidFnFmHEv+btwpLdp3HLRytdn7HWRscpJlJaBcV9X+big8X78MT3mzRKFWEdBTo6iq8R6vf7Yxcu4YFpufh8ue/w3UZkJnLGGNU6mB90taeEElZ4s/BOYsO6vmNQrDuobDqN3SfFBw30JnY9ySrRkb13wrpV+89KXpa1XlfAlVHJn/1pm6RlnU0F9J/Oxl6sPE4RtdHRkdjDY/fJYuw+aY02KWqrK7xXb5pYU9X2WFRWIdxIM5qnZ8ieUyW8y4o9R9YeOGdqsGeFQJPII2dUb+/Ls7KqGiO/+wvt0uLxaK9G2ibMi9Cld+AM/70USDiOY7Za0WxUoqMjNQ8EI65XObtg6dnG6r38yv+uDbAo5be/pLDBuR6ZmZxA1spvdlZw+OxFPDAtV7eqTbW8L79Fu07h9x2n8NaC3aakhwLvK/QeX8zK55kCHUaZGZnrccNo2YCV1Rtur1sJjZRgYNGuU4r2o+TSEFrF2RZMzill9fzbxcjv/sLSPWcwaPIas5PCa++pEjz01QacKb7SmFfPHqLeqCG8MCUDhcph5TNPgY6O1Lz5mllowdsjSMOr/O0722i3MQMoOnTO4/9k0bI9jZLtE3NJGTRTczKvqUW7TuFf83bqkxYF6JLWP9CxMgp0GOVs8Lf1WAFGfLMRh3nG2tFDfiH/GBkFl7Tr8pyo0/QIRtl9sgjDp68X7J7PR8vg4uU5O1AudwZpkQRQHsmO4suV4gtpTMlD0lmi426fTcbBsiK972Erl6ZRoKMjLdro3PbxKizYcRL//GaDNokSMWzqet7PV+0/h2oVdVrua7L89iXlCO+dss7V5fa1//G/1eqdJew/La/xpdg5lzVgoMRFf9l0DNkTF8sKCIl6h85e9JnqQ4ySW5svdjarJxNfWqz8YFbCyBKdFskx4gsxhAIdHWl52R05p01xtljX5B5N6gh+p9UkpVbPfs66Deg3ddUhj7mBnHbly+8C7mTGGEryupdLW/ip/25BfuFljzFYiK9jF0oxdGouVu6T3sVbyLyt+ej97jI8MO3aCwvHcTh09iKq/EQzlXJLCAWc45k+QktqsyCtjtMI+08XY9TMTZJfanRvjOz275oR1uqwTYGOjrQMsLWo+iivrEa/SX/6XSY8VPiSCLAXJMkqq3xPzJ8aPLSM4Bq0Uuf9OKtEOY7DB4v2YeFOZQ2x7WjMD1uxfO8Z3PvlOvGFRUxffQgAsNJtXJxv1x1F73eX4ZlZmwXX+2qNNhMJf7jY/9QlagkH2dIyyKmrDmmXGJ0N/mItft18AoO/WCtpeX+BrCY4gX9bAAU6Onr8et+JMKUGLN5Bhdq3/MqqauxVWX+upnG11sfDEqnnZURP3zFGyiqN6bHift0Vllb4fC93Uk+5nBNBLttzBu8v2ouHvzamKtYKThVd1nX7L8zeDgCYvfmEptt19diz0ENv3raTZidBMmfJMV+JsRCj8hOroUBHR+3S4jCkS32Pz5SOKqomWp/y50E0fn6+pCoEOwUgSvAdvVhGLjWjv6FFgs9nzV5YgKV7hOe90kNxmbrGrmqea3o/1K3OigPfPfPDFsP2JXSvSW2PIzRpqRV5j8O16egFNHthgW7jGVl5/CwKdHTmPSJukNQSHa+LSnYvGzf/mrdLYB++Pl66X/F+/HE/njb1YnXZhxaU3Mr+1nHPf4V++rE/bvX8QGWsyTvXlYTmyNK3r2LYhMCOo3mdcOvp+I1GVUiBRotqP6sZNdNzri5nPv/ZsgO679tqQQ8FOjrzvhzklJiw1mtAi+TUiQ5DfI0w9RtiiJTfifXnu9y5ruTO/MzYpcyUard3mMsV1ql6MGP6GqHL6FRR4M1E/ofB7dysfA9ToKMzn4egjDY6rF1YWvT8io+yV5ADqP+dWPid5SThjXm70PFfi/DLpmOCywhNWOoe6LMWyJslJPjaOZm/3UptSAIvuGCZ3veTlW9XCnR05n1xSK+6Yq9he99JK5SvfPVgtKi6GNwpTf1GZJq1IQ+f6FStZwTx0ZalX20z1+cBAF7nqRLlOA7vLdyLu716irj275aOHSeUd8G3E/efpvCSb0NxedtivexQvn8Paot6cZEA1D3M5Y49ZTVGPi/WH75g4N7Uo0BHZyxXXVk1S0yIMX5k5bE/bsU7v+9R3XPNLNq10PFv7cHzfrsY73Wr7qAeIldcNHCuKCvq3zoJEX6GvZDKX/d6qzldzNOo38De5VZDgY7OFJfocBxmrPXfMLG6mlM1WjHf9izB4DJU94Z3RTxv3Fo3sFW7OTkNBdVNHuu7rlh1xpSV7uOYWDXUtg6rVw8ObJeCqLAQ13Wq5mhKVPY2ZMkfO5S3zyksrUCeGfOpmYgCHZ15P3TkvL29IjC9AHAlKOk7aQVu+WilZpnZ/7ZqO86GO2cKrVi0fuD0tXnG+OICviEDbmyZ6POZlJii6HIFZm3Ik5U+KfSeKFQMb08w610KzPPOb5bvPWNSSrQRHhLs8fexC75z8QlNfeD9qdKhPVh0WsUwDW1f+wM93l6K4wX88xoKsXLQTIGOzpReG2LrLdp1CvtOl2BnfpFmRd98mYhe1OQ5Rt9u9/zHvb2Jb8LXHjznkwko/d2fmrkZv5kwqJlWmdg2gXmtSsoqfSamtc9jhx3ebSc2HS3w+Pvvn622dJWhc+BJdycLpT307RTonC/1nWpD7h282evaEGPdMAew1oQVxOWRGRtd/3Y+pPLOl6JuzXBEhAYLrWYa53PU6nlNIc8s7k/P2iJ4zuWON7F4t7GDBzppMXz8b9vy8cWKg7zf8Q1Wuf14IdrXj1e9XyLMO4DdcOQCFmw/idvb1XN9JncCUNaEBou/r/9r7k7ssWj7Oj4z1h71+UzuywoHDg99tQEpcRF47fZWWiWNSVSiozO9ivvcN8sBWLbnNHq8vVTWBIrOTajt6WE0KaeU4zjkHjqPZXtOa9r2aPIy/gf5Ap9uwZ779B/g6f+uJFZlqKRU0P2Y1h8+j8e+/UvW+t/nqq+iu2jRdhdV1RwuV1TpWrqSX3jJ1UPOXYXX3Gxq2nvozd99ExcVCsCze763gtJyDPxklVfbMAIAO08UYdGuU/ha4iCVFq65ohIdvSm9NuRcVE//dwsW7bqSWXl3oRR7W/v3H3vw0ZL9+GBwO7lJZNqKfWcxdGouAODlW1vigW4ZmmxX6MHEV6Tuiz9Ddp8NXTcCzwLnx6HBDp8HoJxNDpq8RnaSKqqqMXXlIWSlx6NNapzs9dcePIfBX6zFsJx0vHJbpuz1zdT/gxXYe6pE1xLO7IlLJC13yUKDFLqLiQhFQWmF3xD+s2UHsNlG0z74I/dZo/skoAyhEh2dGREFO4McPkdFWtd/tOTK2DAvz9mha6Zr9JDh7iUsr/pp1K0V7yk6zHz7UbLvr4Z31j4hIvadLsFrc3fito9XKVr/nd/3AACmrz6sYaqMsffUlRcSK78lW0GpRbvuG13KLm1EbuterBToMMrowIDjrNO9XMq58Q7aduXrOzid1d+OchrVQYjUsQ90YKeuv1Zj1WZzznvc3513xKLdqN/5Xf7EnHKDZveSvNUHzmq+fZZQoKMzpQGLmovqhw15riorf5mY93fv/rFX+U69nCq6jJd/3Y79p680ADT7Jnn51x3abEig2GuP17w/rOUJUh5mStOsxfxMw6evl72Olbu76qHS4o2K+YSFCD+inNe0v8tghUW71/M1NnbybQ94hdxnjdS2OXZAgY7OzMiLx/y4FV9KaHynZ3fLJ7/fhK/WHPFpHK1ugLorpJzTP/d5ZnB6l5CdVDGuhRGEzrv7x3IDB4cD2HqsAM1fXKAmaQCAM8U0b5Jau/Kl9yq6VF6FKX8exOGzF5nuCRkZJtyD1HlNW3W0cqV+EBhnS82zRlIHD+WbNx0FOjpT3BhZ5X5X7RcvigzXYFh1Ic7xVC5XGP+WearoMvLOe44JJLVmSeyG3ycxUzWztGHr8UKfEYr1KNE5VVSGf2tYCiiXd7soq8g9dF6X7R67IL2a5t4v1+Ff83ah17vLdEmLVpy9BfmuX+dnZsyiTqyFAh2duT/vpg7LMmy/zjYj/kpQwv0UC6vlXVp0bWTkq/+v44CBp3hKVzYe0WYSOrmNG82Id16cvR1Z/1okez0ladWqNEBarzVP249bc1LQHSf4B1VU61GJ3fsd8LwfWC7R8VsSy3C69WTW72XlmmLJ3csrKipkvaUGBQUhJIR6r7s/lq9v7jstgOBaXuc6OlzeuZQyCJh7/bfWJRBm5kEHz1wUX0hnfJO5svxAUUqrcWzkDkdvZVZvuM4K0YlqA+w06z6Ni4UrryQ/PTMzM5Gamir6QHQ4HOA4DhcvXkRubq7qBFqd4ikgvP5W2ivFX2bgXr2jed6rZ1d1kbR+nyvckI9V01YdQnqdGrptXyjIUvszeU85YEWvzNmB6asP4407WuMfXerrvj8KdKTzN9Cl2VM6HLtQiuV7z+DODqmajkZPjey1JznQqVGjBpYskTYAFQB06tRJUYKIObTu3utTdcU5q9I03Q0vFkpO5OZVeoz1U1BajrioMABsnBNWOcfhee6XbcYEOow9yNRMtOtd5dg8qabibSXFROBk0WU8f3MLvP7bLtHlzb6mb3xvBS5VVOFEwSWM6dtcs+2yOlUFY5etLJIbacjtLaNF7xo70GtSTzF2fmkUK0K18g2ppbcWyB+Lg+jP7PGqtNz7uJ+3evwd5aeXlBhnD6t29eNcn/l7jFTKHMlba85xaH7+67im260WbXXAf1LUlgQt33sGW48VqNoGq6gxss7MrtdkId7kOGPPAgujobIQa7nPRq/mrd3Oii5LG4G2qpqT1avJ/7Y02Yxiszd5PpjV5BHeD3kjr/uDZ81viwcA+RJnT2dZ3vlSDJ2a63eUchbyNKUo0NGZ8iDbypeVp8/dZrQ2IvBydm1nQd7Vh6MZE6dSqaq4ksvSqmwf/noDur+1FH/s4B+sTY4q8Vd22Q6eKRFf6KqVEoaeUEpufidUCnFD8wQAwOBOaYLr0uWtnbwL4p0BrNx2iAIdRln4mgLgeVO8OV/jKhQLnRvnG++cLScML1Nx359gY+QAf1oES5z2Ysnu0wCAqavUz4Kt9eV7rqSMmfm+5Bzb9uOFaD9hIWas9R2hd8rQLOx8rS8a1BZuoB/YV64vKef+w8X7eD/XqrSSVZIbI4eGhiInJ0dyVFe7dm3FiSLquRr/spIdXL1srg0Axki6dPLnvjOmD8kf4DGMJGacI6132VHBmEm6kfGG9sysLSgorcALs7fj3q4NPL5zOByICvP/eHI4HNZ/I1RA6JqVcireW8g/wOfvO4QnhrYDyYHOunXr9EwH8aL29rXz7W+FY+M4oPHz801Ng9wHaiA+N4JlRjrrdBrVOBDJabnH9zNRHO9Jq5aQxZcrUDMiVJNtsUJyoDNq1CicOSN9grTGjRvjtddeU5QoOwnUt+oir7YP1hkQzj5Peme1VFU1J2kuqTf/1hrP/rRN72QxRe6vzXFXGjDH2OhB8N/1/HMnKaHm7rlWCi2NWN56piSw5k8Te0kpq5TWSeNMcRlvoGPllyDJgc6yZcswZ84cSctyHIe77rpLNNBJT0/HkSO+9bOPPfYYPvnkE5/Pp0+fjgceeMDjs/DwcFy+bP1W797UXlTO9VkJtF6YvR2ANumxcqM4IzlP9X1frsPqA+f4l3H7Pe7uVB89myag68TF+ieOEdUSriXv2aKLLtkr0BG6NpSQc2uqrb6+sr7wDvmmgrEDOQ3P3UmtnhI6o2b3IFZDcqATFBSEBg0aiC94lZSH0fr161FVdS3K3L59O2688UYMGjRIcJ2YmBjs2bPH9TfrjSmVj4ys7qKy7iWpn/MXy/HgV+txZ4dUnzYBTnaKoZwPcTkPstrRYXolh00Sfu8RMzZqtrtFO0/hwyX7Ndsea9RWR8kisn7eef8NbLMaxKtMgDnOXyxXtJ7U+eTslAc6SQ509BgwsG7duh5/v/nmm2jUqBF69uzpd7tJSUmy0hKQGL1atQhLlR7a5OUHsOloATYdLRAMdPRkdFBuh+kZ9KbkUtp+vAiz1ufh0V6NXYPcSfXQ1xsU7NE6jMx2xO4mseu/fq0o7RJjoAul/ENViJ36eVtPSNwD/5YYfaRIwkz38vLycsyYMQPDhw/3+0AoKSlBgwYNkJaWhttvvx07duzwu92ysjIUFRV5/GcFVr6oWFVafq3d0P7TJbxvRnY67UrmVGK7fFR7Su6zETM24sMl+/HREv6uukIe/07a7OJiCi9VYEteQcBX4aqd64rVs+evVMzfVD1i7fCW7pHWxtaOlxUzgc7s2bNRUFCAYcOGCS7TrFkzTJ06Fb/++itmzJiB6upq5OTk4NixY4LrTJw4EbGxsa7/0tKEB6CyExteqy5Kj23G2muTffZ5bzk6TFioTYIkMvrB5ByingiT0kZHyO6T8uYkmrs1X/G+3PV5bzlu/2QVlu45rcn2tCR1XCIAqFA5/ALjrRZ0USGx+kkP+08raxvEAslVV5cuXZLci4rjONmZ+pdffon+/fsjJSVFcJns7GxkZ2e7/s7JyUGLFi3w+eefY8KECbzrjB8/Hk8//bTr76KiIkODHaU3o/q5roybRFMWnRJUWVWNr9YcQU4jdeM36RmLqHmo6oW1y8NoB0QadvoLJsw6d8439wXbT+L65okmpYKf9znZf7oEsZGhqFsz3GfZA2fUTeFg12vX7GyCb/eb8wrw6bIDkreRX3gJiTUjECQj8NWT5EDn888/x6VL0rsI9+3bV/KyR44cwaJFi/Dzzz9LXge4Mohh+/btsX+/cOO+8PBwhIf73mRGMasxMuu0jne+WXsEE+ZqPwO4lipMnoRQCtYb92spv/AS7vsy1+8yD0xbL/idnFOlx0SeHKe+VERr7tfP8YJL6PPecgDA4TcH6Lovoh2+Z9bAT4TnwPI2e9NxjP7vZgzqmIp3BrXVMGXKyZq9XO5/Uk2bNg0JCQkYMEDezVBVVYVt27YhOTlZ1nqB4Fr3cvtlBnw3olbzW+kZYPK91RLzbDum9pqRfm/N2SK1Iag8UufqMkp81LVu99tkzoTtvPOkZln2y9nY4J0HFgo0fhby74VXekX/sFG4SYnRJJfoPPLIIxg8eLDkKql58+YhN9f/2xIAVFdXY9q0aRg6dChCQjyTc//996NevXqYOHEiAOC1115D165d0bhxYxQUFOCdd97BkSNH8NBDD0k9DMvQahydEBOKDlPjIz1mztYTx3FXh4K/9tl1TetixV7pg1sapVHdaLOTQNx8KNKYeMNh/6Mgy3mHOKRgpu0eTeqILhMawkwzSwBAfA19hifgHXNHZdYW6I25hXiflt7/XiZr/SoGS64lBzrh4eF46aWXJG947ty5kpZbtGgRjh49iuHDh/t8d/ToUQQFXbuRL1y4gIcffhgnT55EfHw8OnbsiNWrV6Nly5aS08WaVvViMLBdPbw5fzcqNSzedm7JjHvZ3z635BWo3/7Voyu8VIHbPl6JxJgI5LoNzR/OWObv7skbmghOrGcKG5b4SbX9uP8emH+fvMbv93LOnJJAR6xXEQe2H9Z6J82uV66/82bE7eq9f7nj9pwoZG+gRlPH0QGAm266SfBmXbZsmcff77//Pt5//31Z6WBdp/RaeKhHQ7y1QNsZvp3nlMWeGVqZsfYIjpwrxZFzngODqcn89c6cG9UVno2ZBXZ9eOhBTvdmvaqubv9YetsJNeKjQgXHbxHCbghmXVtUV7eKs2P7UHZffQOM9wNWqwfu+J+Nn7uooFTZyJ1SOc+N0DgxDL/kEhvR++1aymV8UEFJkRLt0uKkLWjgvcdKjx6t+Qs0TsuY1mLpntN45JsNOCtzzi875p8U6DAso47yt38zL9aL5eLjt2jR1fq9hXs137Ydb3Iin9Th8qWYvFx6t1w5WL9WqepKGTnnbdYj2QgN5j8TD0xbj993nMLr83ZplDLrklx1VVVVhby8PEnVAkrG0SGeOHC4qWUiPl9xEACQEhsha/3Kara6nXpTMmqvVDvzrTH6NQu8s0jvUorb26Xg1836VLuwTEpwIrVE5835yqqlrZ6H6j1ulNoepVqm7tNl+/FYr8YablGamhEhopObnjSwzQyr16zkQKdnz54YO3as5A3LGUeHCHC7j6PCJf9UANQPxqU3Pe+HU0XyimrdsTYuiVpqM7kPBrfH3lMl2BVgweOf+8R77dlx6Aa13G/rVfvPCi631avr+ZWXY33SpJU/953B+sMX8GD3DMRGes5e//aCPbipZSIaJ9Q0NE0cB82Lttx/B7n54YLtJ7VNjEYkPz0//PBDPdNBvLB+06ulpkRHz7eGV/7nf+40q+k6cbHZSbAkKROiSnm+VOoYOLM40ra7mevzeD+/0lvSsxG156FIe3Ib2URnx4lC1+CSe04W4fP7snyW2Xjkgk+g89PGY6iq5nBXJ+mj8cv5VYWuAffrTm7jYvflp/x5SNa6R0RmjDcLtdEx2GO9GnkMHOccH8L7UmQ7C7siTEU37ipGM+lNRwvMToKpAqWUQs+qU3d6zjd22cC5zDpnqJtaxd1qnpIeJb+Gkdeqe/Xjol38PVmX7L7y+YEzJRj4ySr8ti0fz/ywBWN/2qpZBw2p52kLT4mZ5H24Lbpwp7wSGkazdQp0jDa2X3PkPncDGtSOAgAMaHNlVOdkmW1wzJaZEoO5T3RXvL4eQ+ITtt2f3cDsJLhoEeionT1bjNhDQ+/9u3uwewbv53FRnlU4Uh6oo/+72eczjuNklzwYGZL/ue9acCZ0jM6X1ie/34TNeQV47Ntrs9VfrpBesicnKBEq0XH/WG7w4b6499Adnvvw3TCrXdMp0DGBw+HA76Ovw/IxvdCxQTwA3+kBOI5TXawjpyuiXP8a2ApNE5XXRyt50DhHipW6ZpeMWqLLPD1rs6H1yqyVmEhJjlZVha/elol1z92gybbU0iJDlnTuVO/FU5571YCBl1JYSJDrpcxdkwT5o32X8fRoc88O+M6rHreN1qUPzjQWyBxvyFtkWLDwPrz+Dg0O4r0M3Ae7vDKwpPT9O4OnNQfO4ZyfwQL5GtlTiQ7xEBEajAa19R08rvMb7LbPUFJ11SI5Rtbyj/RsKLrMz38dx4gZG2WnRamj59huJK4nh8OBxBg2Si61yJD1jjOcwdjS3afx1oLdmLv1BHq8vdR9AdNp1Q2fg/zGyHqWaM3MPYoeby8Rnd3enVbJCQ0Wfix7n6K0WlGStlkuo63Y+ZIrwc0vm/zPVeXsEWwFkhsjv/POO7hwQbyBnlNqaioee+wxRYkKRN0b1/FoH+LTZofVUFkh797vr9/RCs//st3vOs58ROqpiAgVfjMyi79MLJB1bShe+sYaKaVzSm7bodkN8NWaI651H5guPIO62XafLPb4W2ku5X6epMYLehaOjrs60Orzv2zDzH9mS1onMyVW8Ds5afU7BYTX39HhIbwlZO5yD51H8xcXSN6/c/40Jdfu/tPSA0MjSQ50vvnmG3z88ceSH7hjxoyhQEeGx69vjOTYSLwwexuqOXaLALVSoXKcn/UiEy6ypmnilSJ+lufh8mZkLVtKbKRxO4Nw24aKqmrJc5HpdXoi/FRdmInveLXKpsQe1mbhK7ESOmbn9C563jdGTZYMKPttf9l0XPN0aEFyoBMcHIzrrrtO8obtVgKht/CQYPyjS31MXn4ARxntoqclRUXeVzMQDhwGiUy4eHVBZjjH3WCtDTbvrNBXZTfUrqdNQ5FRvpPjjK3SEpq3qfmLC6S3H5PyQFPwe7t6Yoqsy0L3crn38dSV/N2VX/vfTtfxSm3HZkQc/pdAL8yZuUcF1zleoDYYEf5dPzBwQmC5l9eC7fn6JEQDkl8v9ZrUk3i6dtrMz8T0lN1Iu4eoFTgfXiw8nMzgPi9Rm1TfIn6jT8uMtUd4P5fTSF5KmlkfoVwO72oqPkLnxBkQvTZ3J+/3S3afkp0eo0ZG9n5p57hrVVv8y/t+FghPwxEz/hJfyCTyhtslhrLzIzEmIlR8IQGSH4os5S5X02LU+C0sy2pQC1sNmIXZH6MCTqFB8/xxuJVc/rhRuEGo0cGhmvYXTV+Y7/d7saDFzPeDxQLj5vjSJsNh5V2I1a7iSlCgwxi5DW4DibNUpLLKeifH+buyOlCi3sQeAXLPilWqxjcekd6Bg8+nS/drlBK2nXfrxsx3rew5JV6apJfTxdKmlKFKDHZJDnTKysrw9ddfS1qWJvVUzvlm8/fJa3BH+3qmpqVtaiy2GPTm7a+tiLf/bpD/lmw2ZybI2kCJ/jJn77Gd5Ppb+3r4WWLjRLtmF0ryQakvOyy+cbOXIvUOyuhirgWzz6HrmjU7IRqSHOg8//zzKC6WHlU/99xzihJErnFvwW7GNdcyxbhARwq5b0xygie9OdNihTlDpw7LwnfrjuKFAS1VbScrvZbkQEeuMxLfsgXZIBNnLGbWDGslI5rUlKvsXn7sQinmbDkhfSPEg+RAJzs7GxUV0kd8jIw0truoXTB2jxONuEp0LFB0cX3zRFzfPJH3u9b1YrHtuLrgt1U934Ef5ZZOfJ+rrlRPi19B71Jr9q8UfUg9rXIDoudvboHXf9uFjg3isfHIBcHfz/tzFvLkv326WnIVmlrhIVeGN7DT9Sc50Onfvz9ycnJEb26HwwGO47Bjxw7k5uaqTqDV6XWx5DSqjdUHzum09SvEugQbjYUMRy2rZx7/e6I70sfNk72e+0NpYLt6eHrWFlXpMHLmajWUTVYpbbmFO+X3VNKbkU0W5AY6D1/XEEO61ses9Xl+2075awDuPz0aNUbmuWqMCnI80iHht+Q4zhI9rCUHOpGRkZg6darkDXfq1ElRggKexGvGiPwkJjIE/x7UFs/8IPxQigoLRmm5MbMoh8gcVVju/ffrZv0Gu3JIbXhhI0KlNEF8UYrM08JC3uovgy8tr0RocJCin9tV5Ro4l4oH6VVF8i+CqDDxR973XmPkTBEY+0cONdXobdPisCWvQHUa5JLyO1RVcwgJduCvo+oa3euNxtHRmdyzcPAMO3MhOSA+N5FRz+3Fz/TE4bP6nptRMzfrtm3XIHC67UEZVu5SueelQmXPOy1KHoS2cbGsEi1f+h09316q6vcuLqvEQZ2veRaZ3ZFF6d793UvVHIexP27BTxJKiy6WVXolyNjz4XxBkTZO1LUJQFlmnfHoiQcjelyEh7JzeTSqG63rEV/wM0uvFqzURseb0iTr2Rhc7ZQBev4MzjZMJwovK+t1dfW07cov0jJZhtCk7ZPE5eS8S8dFSR+3S49rY87mE5i14Zjf0nGnT5Ye0D4BClgvpxLGzpOM+Od11RnxvOzdPIGJKgInPZPSfsJCHbd+jQXjHEPIDQjqRIfplBJtKau6Cmx63CPDu2X47kdo/9rvHhdKpb9InVA9hYQ21L6UZTDUxlO3QMfs4ke7OXj2IoZOzUXRZek939QKdjiYejAfOSe/GL9lsm8PHzM4q3Lt2iWYj3upY704bXth+pspmiUsjnXjT1RYMD75RweTU6H9OUtxu/6EmlX8sCEPK/edVRxp+XspXLD9pOvfYiV13rs3rfpS5c9wrsT4BtRCJDdGbtCgAbKzpU1XDwCtW7dWlCC70fKWXb73DH7YcAwPds9gJvs0MiNXMqbPTsaK/1l78EkpsbuhRQL2nCpGYoz4AIJJMRE4WXTZ9ff3D3fF12sO45XbMv2uZ3RAHR1hzKDwLL0oSLH9lb4ICnJg5HcKN6DB8UruXi5jmwPbpfj9/ui5Uoz5cSsA/rnY1HIPVtYfPo8WMl7Aii9Xii+kAytWswuRfLf/8ssveqaDSLTxyHk82N23GNYsN7ZMwv9oICtRzkx5UMdUfL78oKlpkWtUnyZonBCN7o3rCC7z82M5eH/hXrwwoCX6Tlrh+jy7UW1JE7ganaV2Tq+lehtS0qzoWWFifTFvjzgbEOuxOXfbtTxsu8JxorT62VhpLiAn0Dnl9nLjxFKHJMmBzp133on8fOnTsLds2RJTpkxRlCg70fqndk0KadCTQeharXn1jXh8/+aaBDp63BN632bt68dh09ECScs6j69xQk39EqST8JBg/K1DquD3z9zYFB3qx+ObB7sYmCqVDMqDWSvBswLpjZG1+RFLyys9qpYCqXqZ19Xjl3IenLHQ12uO6JceDUgOdA4ePIhNmzZJ3nDnzp0VJYj4Z+QUAv7yEecDOzI02KDUsOenETlo+NxvkpZl591Ge0/c0ET1NmxUSu4h0BojaxHYGTYfHAdUVlWj5Uu/a7I5qb0MxZZipSRE6rX7nxX8JdSMHAYAHcfRIfpwNvI26k2xVg3/vVts+nySRE4xf9/MJB1TopySLuD/d1NT17871I/z+d4Z/HZrJFzV5aS0PQQLJSXlldWinS4sVnNlKUpPk/v5fWnODk3SIofaoRG08tzNzUWWEL96d+YX4fXfdvF+x9JlTN3LdaZ1dqx39t7W68HTIjkGLwxogfY8DzTWORwOpMar6+2jVa8tf1U/VvP49ddKcNJ5upCuf6EP/hzbm/c7p9znbsD3D3dFt6vtflgIXOSav/0kRszYaHYymKSm162RV8J3646KLySVxCf7JZGR5I0aP0nsJWfRrtOi2zjvZ/wxlgpHjOl6QDQTcXUQPyOL+h/q0RAAJLdHYUX9WlGqtxEaos27gE3bePKKDg9BdLj/rCUhJgIJMRH4c98ZANKvZ47jMH31YVyqMGbaETG/7/Cdb6rwktsQENaL31Rx/o5FlwzoKcTYPSU1OQw9/wMGBToW4+wtYkT+qefIth774dnNhIGt8OLs7Yq3OeH2TCTFRqgOCAMpQDGD3Ez/02UH8M7ve9TvWKcb6PzFcjzyzbVSHiVddLUec8gM36w9rHhdPbqXs6i6mvOo/t5xotDQiVr1DrhY+n0kBzoXL17E8OHDJS1LgwVew9KPrYaePynvOVK5w17NElStrzWWinG1ZPQM93xBTmgwO+c299B5j7+VBDrxUWyN+qxkOIt3/9irQ0o8qb2ntK4ulZOesyVl6DdpBW5rWw8v3doSADDgw5WapkeKsf2a4e0FV+6p+KhQXCiVNyCtv2c9S1me5EBn/vz5qKiQfhIiI63/VsIi52VldDAplClokY4gHe6INA2qrQD79gZyUXjqfxyRjYW7TrmqNZXv/upkpyae6I4N4rHxiD6zLyvpQKTHA+L65glYslu8zYW3nEa18eItLWWts/90iez9uNO7vZbz9P627aTf5fTCccCXKw/hbEk5pq465Ap0zPBYr8Z4tGcjAEC/SX/iQmkFOABllWxUDWtFcqDTsKG6DI1ow45jPFTxPOS06pnASukiQy83HpSen6z0WsjSYNA9LR7qjPzEvFhJ2sM9GioKdOSeW47zaqOkBCsnTScOBxvXrPP+9S6J+n3HSQyZss6MJOmGel3pTPNeV67u5fpw366Uh5AWQ+nz3fS/bjZ/tOWwkCDNzjNLxbjuDpwxaR4dL2rOs9rfSM9geEtegex11F4rzg4LYp9JwXJvOEZvKdkMGzfIzQ8jstEuLc7jM+d1J2fwv00Krm8zUKBjMXq/CQhtX+jz8JBgrHy2t6p9xkeF+nxWodHIiOxm02wwu8SL72GVe+g83vhtFy7r2LOK5etCbSeAUTc09flMaXsWJWlRO/u29JGRVe3GNN633M+bjhuehk4alMYCwGfLDgh+x1K7ROp1ZTHOxo16PZ+EGk/6211qvLr2MHreEKrPk0YnmqWb3h0r6XI/zXd9vgYAUCMsBKP6XBuzp1CgoaTZwZoVyO09+OItLfHZsv2YMND/ZKzeOHB44nvpI+jbidTr0OHwLCnbnHcBdaLZaoCuBTZyliskBzoVFRWyMpSgoCCEhFAcpTW9p7oy45nhgO9NwcID2PwUBICrvzNfFcnhc57VaqyMnaM7HS48uQ3+H+yegeHd0k25D3XPg3Q6Jg7AxTLx8YO8j6+8shrDpq3XJU3kCsmRSGZmJlJTU0WDHYfDAY7jcPHiReTm5qpOoNVpfUsp6a4qh9DWjQ6AtHpLZ7mNAQvMLg2Rc38IlUqoLrRTub47BuJzXkrSpSTI0aLGWeo9a9Q4X1KN/2kbTvLM4i2mooryKL1JDnRq1KiBJUuWSN5wp06dFCWI+FfpvCl0ekCZ8eDT8+Gg5nA4sN2Ww074fqdfNh3H+3e3c/297Xih5HWtTI/bQY8hHPh4l8IpITWtrAWVsoIct2u2yo5dacHW76PbpJ4sVD2wQOtLOGCK7wF0byw+KSSfDI0GsQuEK9js+1TO7h/99i/N9qtHcHS6+DJGz9ys/YY1oNU9ISY0WH3/lnCJ067UrRmuel9m8L7m7fqoZKnEjRrRWJQRbXTcb0AzqoBmPNQFm/MK0KaevBmu27t1m2SkLTIRIeU0i/XE23jkAl793w68dEtLTcb4kWv8T9s0eRHRMvjcPaEfqqo5RFydUV5vIRrMmeLd7VlIm9RY/LnvrN9l4qNC8Z5bqSArPIbxMC0V+mIpgKPu5Ral1wNYeARkffZ3hfAd0S4tzmM+GJWbk43a+Ojr2sjIV/6etSFPcNlgkZzzzs9WY+uxQvx98hrN0ieHFtU2WosIDUYNkQlWtaTF/RIisVQoLFg8eHvn723R22s6GBaev1+sOOj6t9mlqoGAAh2Lqbz6VivUXkEtoepiPd8Itb7Pw9wySiqRYZv3b//W/N2Cy/pru2Fmo2qO43D0XKlm26PHnjR2iQ/KNRoF3ihSqxZZIjnUDw0NRU5OjuQMpXbt2ooTZSda34tTVh7CCzLnnpFD6Pf9R+f6mDB3p2771VKdaPe6e+UPQA72D5TYeVbwn+g1B84hu9GVvCQoCACDTdQmLdqHDxbvMzsZAa9hnRoY07eZR1suFoOhg16jkVdWWyvQee+udhj5nXh7OZZOveRAZ906e819YRSrPSeD3aqJ3BuTRYYFo0VyDHblF5mRLFmCNWgnALB1o9qV9zn2Hj7hnv+sxeE3BwAQK9GRt1/3Kha1wazWQY7V8gxWtE6NRf/WyWYnQ5QZIyFrKTFGWiNwlqrkJAc6o0aNwpkzZyRvuHHjxnjttdcUJYqYJzhIuFjyo3va4cnvN+PJG5oILqOE1rdDu/pxrn+rfYjZvUSHFc7zLHS6z5WUobRcuDhHzc/Uvn4cNltkzh4iD9+zlqHnryVZ8fxJDnSWLVuGOXPmSFqW4zjcddddFOhYUO0awkORN06oid9G9dB8n1JvnCYJ0dh3ukTw+8YJ0RjZuxF6Na2rUcqAXs3qYqfGpVgTBrbCi7O3a7pNq3L+9q5ARyBi0bNqqEeTOpi26rBu2ydEDy/fql8TBruRHOgEBQWhQYMGkjds9oirdhcVFuz3DVepOJ4JNlkhdkU93CMDd7RPlbWOmFF9miC9dg2M/Wmryi1dc1/XBpICneyGtfFQjwxMX31YsBttrRphOH+xXLO0Gc27eFto5O8SkaH1leY3LZJjFK2nJyvnnWYmne99yQqnUul4M7WjtR1HSHpVk/UGdKQBAy1K7mia7/y9jaTlmiTUdP3bqJ/QAYekfYk9AO7uVF/2OmLCQ4JxV6c0n88HGNAW4IkbGuOGFol+l1n8dE/d02EEV5sZgZ+rkobJZ8p9XaW/9JrJCoEO0Z/1+olZjF6xgtwb+GaJD+Z+rZIUpEZ7fMfHUqb1ziBpgaMadSW8scX7qWq0Eo4Dii9XoFig5GbFPv/tA+VeGixdS97UJi06XP/BAa9vnsD7OWvvtwz/zJYl9Tdm6VqgkZF1pteNxlfEf13Tulixl/+BYMWL05uSc6nm/HdtKDxEQpgGQ90zweTf2/168zd9QmmZ/2raZi/MV54Gs0+CxgZlpWHpnjO4romyKVSkMGdgUW3Y7fdmFUvnWXKgc+nSJcmNi61cx2wFU1ceQiVP1dVXD3RCxvjfTEiROlKDq7apsTh01rjRZ1PiIg3bl2kYuVU5AIt3n1a8vhHzIn73UBf8Y4o2w2y0TYtDSJADG49c8P1S5bFEhAZj6jBzJlVmLevnexaxNto5yy+XdiE50Pn8889x6dIlyRvu27evogQRca8JDNyndbsoo+4/qft59bZWmL35hKxtT763IwZ/sVZ+ogCYHQUYkgGaXaIjMQFmP5wa1qmBHIWTzPL5dWQ33Pel9mOTLXzqOs23KYfWPRTV4rtqftp4zPB06MGsW7emxClFWArgJAc6111n7g1EAgvfgy02KhQrxvTGde8s9flOqKtl14a18dOj2bjzM3PmP1LnSk5xXZO6opMXWp2/koDh09ejQqfGyFLzYi3bQk0Y2Mrv92qCuiaJNcUXsqn8wss+n/FdV38dLdA/MRrw1xRBD1LvhUZ1o3VNhx5s0tCAiJH85mzCi3P92lGylo2J8I3PGyfocfP5GYlX4POP/9Eeq8Zdr83er+7+gW7p+GBwO1nr1om2RiNl1zg6fh7uS1RUaQmRe5m/d1dbzfZtlR5L/hidT0gZpHTdofOStsVSSQMA7D1VzPv5AT9jhhF5KNAhpvnp0RwMaJOM9+5q5/Odv8CM5R42t7RJQT2N2vYkx0YAuDKb8+3t6sla95fHummSBr05f+UDZ9ib+dtdg9o1NNmOvwE5nVhr58KCp29s6vOZ1EpPb6F+Rn83A+vXvlL+pmwxGlu/OGGK3mMhdWwQj0/+0YG30a+/N/ybW/l2ldcyMJJC71v47qw0RIUp7xSZVkt6KRkLtgTIFAw/Pppj2r6bBWC1FgWN2pPcg1ffZMhCgQ5Bz6Z1ERYShE/+0YG5Yl0+d3ZM9fnMX7q1zuy6Na6NEJHu5a/dnqlqH7UMqnoyuwuoFa43rYzt1wwZdcRLhvR6OP/8mHlBFkvMbtiuFdbvHZbOsqmBTnp6OhwOh89/I0eOFFznhx9+QPPmzREREYHWrVvjt9+s152aNTe2TMSu1/phQJtkzTPZJgnRvG1qxPhLB1+X0Y4N4mUtr4aUwRdr19B2eHaiD4cDhr16PtS9oTE7ElAjPMQ1E7xaVikpOcHTQJkoN7qP9AmdWYrDTA101q9fj/z8fNd/CxcuBAAMGjSId/nVq1fjnnvuwYMPPohNmzZh4MCBGDhwILZvpwkSxYhF/8FB+lyW8TXCEBEqPlKrnJIF7+kvEmqG+92HRfJkD1Z5kKhlVomSGWN9hYVQAbrRth8v9PlM6TV3a9sUtcmRxegSGylDA4zu01R6kwaGIh1T77y6desiKSnJ9d/cuXPRqFEj9OzJP3/PBx98gH79+mHMmDFo0aIFJkyYgA4dOuDjjz82OOXs2fTijYrXFbputbpOtb5hM1NiPf4WC9KEJooUI5TuQAlCjMB68buehB4YSi+vezr7zskmh1i3dyviPcUKrrnc52/AhzJ7Pqoldm8Y/ZJwR3t5HSJYwswrRnl5OWbMmIHhw4cLZgBr1qxBnz59PD7r27cv1qxhd4yUlKs9Z/Tmb5yPyfd2MCQNRomNCpUX2GkQmLx9p/5zW5khkAMNO9n+al+8cUdrVdu4K8u37Zs7qQPFsUSrYKBWVJjhE1Wz9kLVJjVWfCE3dTSeXV0NZgKd2bNno6CgAMOGDRNc5uTJk0hM9JzNOTExESdPnhRcp6ysDEVFRR7/GWlEr0a4KysV00wakh0A+vH0UrI6OQO4aZFf8M1g7g8FEEQpJdVq0eEhqh/EYkFBq3rXHnSMPYMFKa2R957LzuggR44sP+0TtSS3u3ibevICIz0xE+h8+eWX6N+/P1JStK0HnThxImJjY13/paWpK96VKyosBG//vS16C8z2qzcpk08OkDizuVJm9+xRWnUlRMrW1O7SLj1DWMfw80uyvpmJ4gvZUEk5/0z37pT+vuGhzDwaRdWtaUzJSZJBtRN6YOLXPHLkCBYtWoSHHnrI73JJSUk4deqUx2enTp1CUlKS4Drjx49HYWGh67+8vDxN0mwncVH8pSNmPgS0fMxrPeFjusBIzjXCrjWItkqgYnbx+OniMlP2q/SwO6fX0iwNQreX3LSVVVarTQoA6wV93609KrpMkwRtxg4SOjVP9fEdyFArev0emSkxspavFxeJJ65vjJtaWjegZiLQmTZtGhISEjBggP+uj9nZ2Vi8eLHHZwsXLkR2drbgOuHh4YiJifH4j2ivZbLweVVyw2rZK0arbf04IhsTBrZCd4HJHTUt3rZGnKRaWUWV2UmQ5buHu5idBB9lFdoEOmLcg3czeq01rOs5BlF5lfhx85XMSLpLvQ5P6NaOiwqVsjWmTHtAXjOKPi0S8MxNzWTnbywFzqYHOtXV1Zg2bRqGDh2KkBDPxm73338/xo8f7/p71KhRWLBgAf79739j9+7deOWVV7BhwwY8/vjjRifbtpSWRFzXtK7gd0qudy2DhqYKR4T1TkFWei3c17WBYNrcPxZ7DoSLdDUOkDiHCWJXWv9W10qMxQaK1ILcGELKA18Khp5LvH4d2Q2P927s+lvPB6n3T8B3z0eGBmOwyp5uftMgch0oPf6EmvKqoKQMD8Lnrixjm4n4Y3qgs2jRIhw9ehTDhw/3+e7o0aPIz893/Z2Tk4PvvvsOX3zxBdq2bYsff/wRs2fPRqtW9usWqRXnzWBWdK20aFfLN0a+KSakkNv4Ts7yYlM0GDXxo9lVbGY08lyw/SQemLZedLlBHVPRq1ldfPwPfXotlkpoYyJFtAV7QylRMyLUo0G0UNu/lc/2Vr2vXs2EX9ycPv5He4SHKAsCpGClRETp+EGp8exMQ2P6HXLTTTcJPtSWLVvm89mgQYMEBxS0g+HdMjB11SHNtqdmIEAtHkLZjWqr3oYZ6sVF4okbGosv6MajREdsWZHvrTZXFet2nChEdHgIGtSugREzNkpap29mEvro2C5h/eELAt/ICz5Z6sZrpEsC1Z5aPGBjIsWrpPSuvZPSkcQIoQrTYfZLlDs2ziRxeenWlppuT26phB49pMbf3EJ0GZZuCgBYNe562UW8MRHXMkexEik939aiwmS8ZbJ12nVxprgMAz5ciZ7vLPP5zuwegXzkPkC1unfEXmzc02XeZaN+z1LuvUZ1ow1IiX/REdZr/8MqCnRsTuym9h4ETMuAwzlYotFDp5vl8/s6Sl5WzwdsLRljDAWCo+cvuv7tPX0Ii9hPobVJufeGd0sXXUb3Btlmd4m0EdOrroi++Kqu3h3UFjtOFKJ/q2TZo13K0Zpn28/2a867LItv1nK18NPzzJueJTpyth0IWal7ScXvO4QHF7Uqre4dsa1oca00qlsDB85cCzzbpcVhc16BBlvWlpRq+xyB3pdaUVv9Ta6hQMfCBrRJxryt+X6XibjaWM49M0yMCcffO2bqmjYAeJ1nSPrQYGm3p9UfwOI9JtjIpszoJuzOiNNw1m2snglzd3p8V1Zpre7tVve/J7qjoLQCOW8uUbS+FperVqXWejcCFztW5yC0jGQlPlgqkKKqKwtLlNCG5Okb9RvQSoycRpI+mQ9DN4kSYpmpmXmT+1gwrARcenr79z2uf+cXXvb4bu+pEsH1zLoEzXpAyCoJVJjG4CAH4t0GKGXx8huabUyPRzFieYiz2zdLAYU7lpJFJToWlt2oNlLiItA8SbjKhG94cDOriQLhwQroNwaGFnIaXStyl9Vw2aIuiwxKeLGMSnWk6JeZhNxD55GsYioABxyIDAvC7e1ScKm8Sn5nCQ3uG3/5X2p8JF64RdsOIUpVGzMOZECgQMfCHAAe6tFQ9nr+3hSaJNRE63qxtmvQWjM8BMVl0sYt6S1hDA0xYhmy3AxeL6y+DWopRGSIhUrGnihm9UAUewkZmpOOBrWj0C4tzk/XeGk+GNweAPDw1xtkraf39do5vZbi7tTEk9RmCkagQMfuZA4YGBzkwJzHu8nfjcpr2jsD0zo/e7R3I7y9YI/4ggCCg9RndD2a+A+WdG2MTM0UPYgFlVboieWPUYFRcJADN7TQdlwhM9qIsTaUhVpS85KbWibiwe4Z+ibmqm8f6qLrYIpyUaBjYRo8j3kpqV5yz6+euL4xujZUN1CginEOeYXqdbIEBOogbnLpVbI1M/co+rdKRmxUqOiDgLVAxxqlbMoS6f1bmHHuQ4KCALBVisdH6zPz5A1NPEaW1lM3nXukyUVldBam9CGh9xv/Mzc1E7zQpb7BsXajEGsZ9/M2PPbdlRGQxe6TamtEFi71vKY0sXIJXqXMQEeLX8oqZ0tqXmmxy9cUFOhYWJKERoF8N7UeRbeqq668/lYzdYUVGHF0k++VPoChHa3afw4XLpZj32nhnlUAIDQnplld78X2mhjjWVpo5aqY8kp2S1YYaUZnORl1aogvZDAKdCzMX28rb1a7Z23/lqJhLio0c3y/Vkk4/OYAv+va/TRLmdeqymIXWxUDyVV6yryv+gFtkg3ZrxVJPVbWAjKzx+biQ4EO0UQaQzPVGsn5du39lm2kKfdnYcHoHq6/vTO+m1snGZwi6fTOo9cdOi+6TLVA9YlZQyGIPSju7VLfoJTob0gXfces4XsZVPMYbp5UEwBQw4BhGaxWperEYqop0GHQxL+1Rqt60ktr3L0wwHMCTb7Zw/Wo078rKxWP9mqEbx7s7Hc5oYdHpVD9gUHkvlk6ff9wV/y9Yyq+f7irximSLiwkyG/pXk+BEh8WsPA2KvRAYfHNFAA6NIhHLw2GQFBDqzOjVxX176Ovw+R7O6BzRi2f76T+rnwp+8/9Wbg7Kw2zR8rvmWo2pfea3KpRFm8bCnQYdE/n+pjxYBfxBXk0Tazp8TdfFz896vRDgoPwbL/mot2qhUxffVjbBHm5s2Oq3+8bS5itmE/DutF4d1BbNFS4vrt/DWyleht8rNxY1Qis9bqS4t1Bbc1OgiJipWQPiEymGRYi7ZHVLKkm+rVS9vLiT1qtKLz19zZo4pXP6uHGltK68ivNuwIJBTo2I5Rlsz4isftEf3rgGwDxuZv5JxjVysu3Co+wyvdriGXiz+gxnQeLr18Gs2IVgV2HL+jVLMHv972b1UX3xnXwaK9G+iTA7cb8anhnRIYG4/27zQkqYyNDJS33WO/GHn+P7tNEj+RIdnu7FFP3z4cCHWIoVqoDNr14I/55nU6Z5VX+iuWVxJ1P3NAE8VHSMj8inVCtaR2e6VOIvsRui5DgIMx4qAue7afTS4pb9tSjSV3seLUv7mjvvzTYbBGhweja8FoVXb9W/G3ylJbsyl1vYPt6ivajJwp0ApAVqjL0LoCKN2CKCz0OITKUndFGtcBCSSNfic64/s3RoX684m3WjFA+FqtR7wJJMcrnrNKq15UZ5CQ9yILDXNQI47/2lHb7ltvUgcUzRoEOo5QGI6yUmKjlPsOxVenxEJeyTZ8lWMx5GDeip7rSPrmn3P1nDRepwvTedud03wa3UjRKqGHYlACWoeG9EqMi2FUjrVYUBnpVH21/tS8iDZrAl8UnEAU6FjW8m/IMygoDjBmdAetRsFAvPlJ8IWJLbdPiZC3vPnpzH4mNUFeM6Y1Jd7fDXVlpsvbl7imN2n29elumJtsxgt93QY2yxpAgBza8cKOqbahJyqTB7THzn1d6gmamxCA63LigS01JoV5oriuLap4sr9W/lV7qx/ZrhhoG3ph66dW0Lsb0bYbMFN+u36z8HuyHvPrTshS0ZXIMujepg4d7NMTXaw7joyX7Ja2X06g2/tx3FjERIQgNDkKd6DCcLSn3u0792lGoX1vd+FXR4SHY/NKNknszOSW4jRt14I2b8d26I5LWY6Cm0hChwUGyz6kafDUAXRvWxp9jeyNRZeAht3aBxbybvRSRK9yurfTaUTh8rtTjazWTIZrZRkdK1UuwCbmhcyAwLTkcDoz06hHh/h1hJ+DTSqOEaDx385WxrJ65qRk+X3FQ0jQH/xrYCnO35uPWNs4qB+POTJyCauKsBvEY07cZGtWNFh0LZ+4T3XHLRyuVJk9zUWHBuFRRxf+lRqddi1JzLeLvtFrqB3K1Qg2AGAp0LIDvoSh0P7J+SUp5e5YbxKkZlXnuE92x7Xgh+mayO3qwWnYLJljmfa6lBu2xkaEeQbG/1bQKktW88PgL4tUwIv5vlxaHxbtP678jlewQYLCC2ujYjYR7g/UbKCJU2mX544hs9G+VhPcHt5O0vLNL6pi+zVyftaoXi3s61ze8hEXPvVmptIjtK1E+71Mv9V6z0m/Gp1ziBFxixxlhs16FatikXwkTqESHUe75AV/WIDdfZD0fDXIAzgFqb2ghrTFmVnotZMnocfJor0a4s0M9JDDYWE6qKI17TpidmZp9WQ7LSdd0e0qPx/v+9Lcdrc6ZlnnCnC0nNNlOVgPlXfqlsmP8wHr+bjYq0bECjS9iFsfRWTP+Bte/U+L0661k5SAHAD76R3uzk6Aps8cpefnWlpoGe0pLZryra/V8cL10S0sk1AzHKxr2lCotq9RkO1Yv2XLS4pryV81/X1d9J0O1GyrRIUxIjInA4TcHmJ0M5jVPisF9XRvgm7XSerl4M+KN2Uq0frAqLtHx+Vu/B/7w7hl4oFs6M0FF08Ro7D1Vono7Zk6sqwd/U7ANp/GPZKESHUaJZUFq8ijW2+gEAu/fT89xLqLcRkqd9kAn3fZDoDjSMbJE58r22QhyACAkSJvHEN98dnI9rlEDay1yWLOrle2ESnQsgK8XktAbn1AQw0rGxko6zOb9+8k5K3JPYd/MRPRpkYAODeJRM4LmynL653UNAWjbZsP7d5X6sJLVRoduIVX8VQk1ZGgmcHoh1Q4FOgHIzDY6dpmiwkxip9D71w0JDsKUofwlOWZnpmZeDkLtHNQEEkrXlbOemjG09CI2lo4RThZdRjMJ42HxXXKv39EK2Q1ra58oFfxVXXlj8JJgClVdMUppyUdmSqzGKSGESOXT1kbibexTwsezYvOkmrizQ6omg8Bp7Yv7shSvq1Wse7a4TPY6TROjcWPLRAzp0kDb0hyqu2IKlehYgJzu5WqH+yYmoTcyW/AubZH6rJJSIPLKbZnoylipg5O/qShiI42pLlVSqvT76Ot0SIk2tGhzJEfDujVw8MxFQ/dpFCrRsQAqlrQhnt+UfmbrU151Jd4Y2arXR1qtKLx8a0u8f3dbXfejZKgCh8PBbLvBe7rUlzx4qhbYPAvaoEDHAlgc94Zoz4ySaquVjndvXEfzbWo7jo6y9byf0Yw+exV7oFsG7mifqus+IiWOqmyVaz48JBj/HtTO9be/WcH1fEboOa6ZUSjQYZTN8jnizSuzdQCo0ioHtvHFY/YAg+KUpc+nRMfOP6JOejera3YSXPRo5P/w1V6CAHSZGV2oZCvGBj01qY2OBfAWY1v0la9uzXCzk8CsKjndLGxC7gOB9aved64rIkarnpghwdIe/vdnN8DyvWeQ00i/9k5aBart6se5/j28WzqKL1egtLwK9WxQymIkCnSIIT75RwesP3wet7RJMTspbODJB6slZvgPdEvHN2uP4PZ2gXcu9YjvtXz7Zj0Qs5MHuqVj2qrDste7oUUiVozpjZQ44zpuRIUFo7S8SvZ69eIisez/eiE2MhQOhwOj+zTVIXX2R1VXjBLL0K2WoQ5ok4xXbstkYrwNFjkcDqTESntLa1g3Grsn9MOku9vpmygim5yB/8gVSkunn+3XXPE+69eOklwCpIQzeL65dRIA4M+xvRVvK71ODcQb0APLztcqlehYgMPhwBt3tMZzv2wzOylERze0SMCYvs3Qqp74WEgREhteEvnUZPje7Rmo6kqc0qorlu8B5yF9OqSjuQkhACjQsYyeDDW0I/pwOBwYqcFcO3Z+MzPi2NQEJyN6NdIsHd6s2i6PWIOdLy+qumKU75w5ntmvnS/KQPDSLS09/qbfk593l+FohnuATLg90xY9VIj1UP7hHwU6jHJvIEnXsP1IqZ4iV3rIOHVtWAtPXq/N7NLuvGtOlN5vqfH6Ts1g13nixvW/0tZmWE66uQkJcHYe0oCqrixAabRe2+AhxIn1mP4mKDZBqVsCZ/4zG6eLL+ucIBX4zqU9YxNN9WqWgK2v3GSr0jAlP3t67SgcPleqeVoIlegwS3yGavEnFNXpWwf9UvzMnl1djvgo7V4snrqxCQDgzg7XRhO28/1spyBHKbNHILbx5UUlOqxyz94dDp7idRtflCSwpdWKRN75S1f+8KlW0u7CrxkRwrcLRZ7q0xTt0uI02NIVd7RPRdeGtZEUE4Gf/jqm2XaJMZRUTbtPyMzKgIAxEfYIEahExwKGd8swOwnEQqz+5v9/NzXTfR+f39cRcQpLYPiG3x/Vp4naJPlIjo20/G8ZqIa6tS2T6t6u9V3/fvpGNgYGnD2ym9lJ0AQFOoxyb3jYtaF+Q5UTNtAD7Zpb3UbP1qPi6saWieibmaR4/d+e7I4hXeqLL6iRlNgrb/qZKTGG7ZOoo2QwwvCQaz0Mo8LYGCOoYd1os5OgCQp0GOVddeWNHovEDvgCGb0n7lTbealxQk28dGtL8QUBpMarr4JYPrY3dr3WDzXCrVeNEBGq7yPmbx3qAbBHj60WyeYGsrtPFpu6fz1Z784JEA6Pfzvg/UhQUwBAhQdsmHR3O4z+72azk8GMNqmxuLer/CJ/lv1naBZen7cLj6voFh8aHASGBwHm1aNJHTSqG+1RHaOHd/7eFiN6NkKTBLZKHpTE6jQ9jn6oRIdR0eEhuL55Aro3roPEmHBFb6FCAY1Nh+OwnIHt67n+TVkcMOfx7rgrK03x+p3S45WtqOCGkNooulHdaEwd1gkd6itMm0UlxkTgldsy0Tihpq77CQ5yoGliTeaqfqVcH9c11W60e9aOnzVUosMoh8OBqcM6qdoGBTSByU5ZntRB8l6+tSVCgoOw/vAFnVNEiDgphTMfDm6Hdq8t1D8xhEp0rKp5EjVMJNZXVe0/kHHvcgtQKaVVPNg9sHuK8pWwNEv0LN3y1+vPjAIaZ3snO6JAxyLcB0777z+7Ir1ODdF1hG4WKuVkjxa/SVaDK9Ujgzsb1yNILbE331b1YvHa7ZmYOixLdFtKT6GSGMn993q2X3OFe7YvsxvWmo3vuv7h0WzjEyLD2L7NkVGnhqZVaqygqisLaitxYDKht1x6+7Wnbx7sgp35hWifJr09iNnz2/zzukZYuucM/t4xVXCZ+7PTRbfTu3kCVh84q0ma5LZ3CA2mNwfiKSbSd6TnMLcu52/d2VrT/WlxBSbFRmDp//XC8r1nsGLvGQ22yA4KdAixiciwYHRsUMvsZMhSt2Y4Fj3dU9U21o6/AUmxEYoDnZpeo7/adfJMYpwuGf7vQ63HRqsRbrFueQajqisLkvrCSVVU8jjfzLs3NmOARvqxlEqKjRBfyI33fXFf13Rc3zxB3jZkLR1Y2qbKn/7AbsRKBcVjaXlX2AsDWqJVvRi88/c2stYLFFSiYxFavmRSAMRv+Zje2HDkAm5upXzUXGIeqdVw3vdSZFgwpg7rhPRx8xTtV6xBtZg60eGq1mdNPQ0GSSTypMRFYu4TPcxOBrOoRMeC1LaroJJ5filxkbitbYqi4duJPqwQk/93Q57ZSSAW43zZjLw6EqTeI0gHOjq7hDCAYitp/AU+WpVUym2MfK6kXNX+KqurVa1PrOuHEdno0aQOfhyRY3ZSXOS0Ubuzg3AnApZQ9moRVAhjb0FUn6iakWdQy5FoYyJ8e+hYWc1wex2PnlrVi8U3D3ZBq3qe7Zqskh20qx9ndhIkMT3QOX78OO69917Url0bkZGRaN26NTZs2CC4/LJly+BwOHz+O3nypIGpNpfUm6BpIv/8L1a5iQIJBTrS2Cng//ahLmiXFofP7+todlI08f7dbdEloxbG9GtmdlKYFBEajD4tEtC1YS3UrxVldnIE2XE6CVMbI1+4cAHdunVD7969MX/+fNStWxf79u1DfLz4OCB79uxBTMy1QakSEuT1mrCaenGRiAwNRo3wYISIjLI278nu+GbNETx1Y1Pe76mNDrEK70z3UnmVn2X1To22ujWug26N65idDM3c0T4Vd7S3RlWGWaYMVTetjxHsOLyCqYHOW2+9hbS0NEybNs31WUaGtKHDExISEBcXp1PK2BMWEoRNL92IoKslWP5kpsTizTupm6GVBJlUtsp6cOCdvmpGMmH3ZNnxwUDMxfht6WKVdJpadTVnzhxkZWVh0KBBSEhIQPv27fGf//xH0rrt2rVDcnIybrzxRqxatUrnlLIhIjQYYSGm1zYSHRhdddUk4Uq15oA2yYbuV6rb26WgbWos2nuNAq6yJzchlpAca40u+la5HU0t0Tl48CA+++wzPP3003juueewfv16PPnkkwgLC8PQoUN510lOTsbkyZORlZWFsrIyTJkyBb169cK6devQoUMHn+XLyspQVlbm+ruoqEi347EK1t/iA8ljvRrh02UH8NItLQ3d77wne+BCabnPpJms+GBwe97PvbvhRoVdGxHW7OksCFHrmwc7I+/8JbSmQRc1ZWqgU11djaysLLzxxhsAgPbt22P79u2YPHmyYKDTrFkzNGt2rbFbTk4ODhw4gPfffx/ffPONz/ITJ07Eq6++qs8BEKLS2H7N8WivRqhpcM+bsJAgZoMcf7zfdB/u0dD1b84y75fEThrVrYEDZy5qsq0eTaw1oab3qwWrNQ6mpio5ORktW3q+ybZo0QJHjx6VtZ3OnTtj//79vN+NHz8ehYWFrv/y8mhwL2pSwBajgxw7Mat0kkpFidO7g9qanQRm/PIYO+MBuTO1RKdbt27Ys2ePx2d79+5FgwYNZG1n8+bNSE7mb2sQHh6O8HB7DbFOCPFFATwxg/eksIGqZXIMMlPYrHIz9Rd66qmnkJOTgzfeeAN33XUXcnNz8cUXX+CLL75wLTN+/HgcP34cX3/9NQBg0qRJyMjIQGZmJi5fvowpU6ZgyZIl+OOPP8w6DMuht1FiF82TYsQXIoQENFMDnU6dOuGXX37B+PHj8dprryEjIwOTJk3CkCFDXMvk5+d7VGWVl5fjmWeewfHjxxEVFYU2bdpg0aJF6N27txmHQAgxUaf0a2NuGVmgY8dB1QhRg+UCVdPL3G655Rbccsstgt9Pnz7d4++xY8di7NixOqfK3qiIn9iFe8CRpFHjagphiDx0xQBsjyfFZhNpQgiRqVczbXqsyM2u29UXH8mdBI5nBEaktyOrFGyaXqJDjGeVi5MQOcyqTro7K82U/RL2rB53PVLirDHYnxB2y2WUoxIdQghxIzdcCqZcNKC5x9fxUWHmJYQIols0ADFclUqIZv7Wvp7ZSSABINgt0gnk0nKWnysU6BBCbMN9ioieGrXZIcSf4KBr0Q3LD3stJcdeafjfs2lddKgfBwAYlMXuzPXURicABfJbB7EX70s5MjQYlyuqVW0zKIhuECKde6BTZYNIJzpcPCxYNqYXii9Xok50OGY81AU7ThShI8ON8qlEhxBiWXFRntNnuDdIlvvM+XRIB9SJDsPXwztrkTQSIOpEXxt5PzI02M+S1pDVIB73dW3gd6Lh8JBg13FHhYWgU3otpl8QqESHEGJZ/npayZ3k8+bWyejfKokGAySyhIUEYfurfeGAZ+mOVTkcDkwY2MrsZGiKSnQCSP1aUQCAtmlx5iaEEJ2ofcxQkEOUiA4PQQ0JVT7EHPTLBJAlz/RERRWHyDDrF68Swsc9TrFBcwlCiAYo0AkgIcFBCKEYhwSIICqdIYSAqq4IIbZyLbjp1yrJxHQQQlhBgQ4hxDYGd7oyHUOn9HhEhAajW+PaJqeIEGI2qroihNjGqD5NkJUej6z0WmYnhRDCCAp0CCG2ERochF7NEgzdJzV6JoRtVHVFCLEtCkIIIRToEEJsy4hAhzp3EcI2CnQIIYQQYlsU6BBCbEvuNBCEEPuhQIcQElAy6kSZnQRCiIGo1xUhJCDMeiQb87aewOg+Tc1OCiHEQBToEEJsy70xcueMWuicof34OtSzixC2UdUVIYQQQmyLAh1CiCU1rFNDdBkjCluoezkhbKOqK0KIpeye0A87ThSiXVq86LLt0+KQe+i8rumhqitC2EaBDiHEUiJCg9GxgbS2NqP7NEVMZChuapmoc6oIIayiQIcQYluRYcEY2bux2ckghJiI2ugQQogK1EaHELZRoEMIISpQGx1C2EaBDiGEEEJsiwIdQghRgaquCGEbBTqEEKICVV0RwjYKdAghhBBiWxToEEIIIcS2KNAhhBAVqI0OIWyjQIcQQlSgNjqEsI0CHUIIIYTYFgU6hBCiAlVdEcI2CnQIIUQFqroihG0U6BBCCCHEtijQIYQQFajqihC2UaBDCCEqRIaFmJ0EQogfdIcSQogC93ROw75TJejWqLbZSSGE+EGBDiGEKDDxb23MTgIhRAKquiKEEEKIbVGgQwghhBDbokCHEEIIIbZFgQ4hhBBCbIsCHUIIIYTYFgU6hBBCCLEtCnQIIYQQYlsU6BBCCCHEtijQIYQQQohtUaBDCCGEENuiQIcQQgghtkWBDiGEEEJsiwIdQgghhNgWBTqEEEIIsa0QsxNgNI7jAABFRUUmp4QQQgghUjmf287nuFQBF+gUFxcDANLS0kxOCSGEEELkKi4uRmxsrOTlHZzc0MjiqqurceLECdSsWRMOh0PTbRcVFSEtLQ15eXmIiYnRdNusCIRjBALjOOkY7SMQjpOO0T6UHifHcSguLkZKSgqCgqS3vAm4Ep2goCCkpqbquo+YmBhbX6RAYBwjEBjHScdoH4FwnHSM9qHkOOWU5DhRY2RCCCGE2BYFOoQQQgixLQp0NBQeHo6XX34Z4eHhZidFN4FwjEBgHCcdo30EwnHSMdqH0ccZcI2RCSGEEBI4qESHEEIIIbZFgQ4hhBBCbIsCHUIIIYTYFgU6hBBCCLEtCnQ08sknnyA9PR0RERHo0qULcnNzzU6SoBUrVuDWW29FSkoKHA4HZs+e7fE9x3F46aWXkJycjMjISPTp0wf79u3zWOb8+fMYMmQIYmJiEBcXhwcffBAlJSUey2zduhU9evRAREQE0tLS8Pbbb+t9aC4TJ05Ep06dULNmTSQkJGDgwIHYs2ePxzKXL1/GyJEjUbt2bURHR+POO+/EqVOnPJY5evQoBgwYgKioKCQkJGDMmDGorKz0WGbZsmXo0KEDwsPD0bhxY0yfPl3vwwMAfPbZZ2jTpo1r0K3s7GzMnz/f9b3Vj4/Pm2++CYfDgdGjR7s+s8NxvvLKK3A4HB7/NW/e3PW9HY4RAI4fP457770XtWvXRmRkJFq3bo0NGza4vrdD3pOenu7zWzocDowcORKAPX7LqqoqvPjii8jIyEBkZCQaNWqECRMmeMxBxdRvyRHVZs6cyYWFhXFTp07lduzYwT388MNcXFwcd+rUKbOTxuu3337jnn/+ee7nn3/mAHC//PKLx/dvvvkmFxsby82ePZvbsmULd9ttt3EZGRncpUuXXMv069ePa9u2Lbd27Vruzz//5Bo3bszdc889ru8LCwu5xMREbsiQIdz27du577//nouMjOQ+//xzQ46xb9++3LRp07jt27dzmzdv5m6++Waufv36XElJiWuZESNGcGlpadzixYu5DRs2cF27duVycnJc31dWVnKtWrXi+vTpw23atIn77bffuDp16nDjx493LXPw4EEuKiqKe/rpp7mdO3dyH330ERccHMwtWLBA92OcM2cON2/ePG7v3r3cnj17uOeee44LDQ3ltm/fbovj85abm8ulp6dzbdq04UaNGuX63A7H+fLLL3OZmZlcfn6+678zZ87Y6hjPnz/PNWjQgBs2bBi3bt067uDBg9zvv//O7d+/37WMHfKe06dPe/yOCxcu5ABwS5cu5TjOHr/l66+/ztWuXZubO3cud+jQIe6HH37goqOjuQ8++MC1DEu/JQU6GujcuTM3cuRI199VVVVcSkoKN3HiRBNTJY13oFNdXc0lJSVx77zzjuuzgoICLjw8nPv+++85juO4nTt3cgC49evXu5aZP38+53A4uOPHj3Mcx3GffvopFx8fz5WVlbmWefbZZ7lmzZrpfET8Tp8+zQHgli9fznHclWMKDQ3lfvjhB9cyu3bt4gBwa9as4TjuSkAYFBTEnTx50rXMZ599xsXExLiOa+zYsVxmZqbHvu6++26ub9++eh8Sr/j4eG7KlCm2O77i4mKuSZMm3MKFC7mePXu6Ah27HOfLL7/MtW3blvc7uxzjs88+y3Xv3l3we7vmPaNGjeIaNWrEVVdX2+a3HDBgADd8+HCPz/72t79xQ4YM4TiOvd+Sqq5UKi8vx8aNG9GnTx/XZ0FBQejTpw/WrFljYsqUOXToEE6ePOlxPLGxsejSpYvreNasWYO4uDhkZWW5lunTpw+CgoKwbt061zLXXXcdwsLCXMv07dsXe/bswYULFww6mmsKCwsBALVq1QIAbNy4ERUVFR7H2bx5c9SvX9/jOFu3bo3ExETXMn379kVRURF27NjhWsZ9G85ljP7tq6qqMHPmTFy8eBHZ2dm2O76RI0diwIABPmmx03Hu27cPKSkpaNiwIYYMGYKjR48CsM8xzpkzB1lZWRg0aBASEhLQvn17/Oc//3F9b8e8p7y8HDNmzMDw4cPhcDhs81vm5ORg8eLF2Lt3LwBgy5YtWLlyJfr37w+Avd+SAh2Vzp49i6qqKo+LEgASExNx8uRJk1KlnDPN/o7n5MmTSEhI8Pg+JCQEtWrV8liGbxvu+zBKdXU1Ro8ejW7duqFVq1auNISFhSEuLs4njXKOQWiZoqIiXLp0SY/D8bBt2zZER0cjPDwcI0aMwC+//IKWLVva5vgAYObMmfjrr78wceJEn+/scpxdunTB9OnTsWDBAnz22Wc4dOgQevTogeLiYtsc48GDB/HZZ5+hSZMm+P333/Hoo4/iySefxFdffeWRTjvlPbNnz0ZBQQGGDRvm2r8dfstx48Zh8ODBaN68OUJDQ9G+fXuMHj0aQ4YM8UgnK79lwM1eTgLPyJEjsX37dqxcudLspGiuWbNm2Lx5MwoLC/Hjjz9i6NChWL58udnJ0kxeXh5GjRqFhQsXIiIiwuzk6Mb5JgwAbdq0QZcuXdCgQQPMmjULkZGRJqZMO9XV1cjKysIbb7wBAGjfvj22b9+OyZMnY+jQoSanTh9ffvkl+vfvj5SUFLOToqlZs2bh22+/xXfffYfMzExs3rwZo0ePRkpKCpO/JZXoqFSnTh0EBwf7tJo/deoUkpKSTEqVcs40+zuepKQknD592uP7yspKnD9/3mMZvm2478MIjz/+OObOnYulS5ciNTXV9XlSUhLKy8tRUFDgk0Y5xyC0TExMjCEPqLCwMDRu3BgdO3bExIkT0bZtW3zwwQe2Ob6NGzfi9OnT6NChA0JCQhASEoLly5fjww8/REhICBITE21xnN7i4uLQtGlT7N+/3za/ZXJyMlq2bOnxWYsWLVxVdHbLe44cOYJFixbhoYcecn1ml99yzJgxrlKd1q1b47777sNTTz3lKnVl7bekQEelsLAwdOzYEYsXL3Z9Vl1djcWLFyM7O9vElCmTkZGBpKQkj+MpKirCunXrXMeTnZ2NgoICbNy40bXMkiVLUF1djS5duriWWbFiBSoqKlzLLFy4EM2aNUN8fLzux8FxHB5//HH88ssvWLJkCTIyMjy+79ixI0JDQz2Oc8+ePTh69KjHcW7bts3jZly4cCFiYmJcGXZ2drbHNpzLmPXbV1dXo6yszDbHd8MNN2Dbtm3YvHmz67+srCwMGTLE9W87HKe3kpISHDhwAMnJybb5Lbt16+YzxMPevXvRoEEDAPbJe5ymTZuGhIQEDBgwwPWZXX7L0tJSBAV5hg/BwcGorq4GwOBvKavpMuE1c+ZMLjw8nJs+fTq3c+dO7p///CcXFxfn0WqeJcXFxdymTZu4TZs2cQC49957j9u0aRN35MgRjuOudAuMi4vjfv31V27r1q3c7bffztstsH379ty6deu4lStXck2aNPHoFlhQUMAlJiZy9913H7d9+3Zu5syZXFRUlGFdPB999FEuNjaWW7ZsmUdXz9LSUtcyI0aM4OrXr88tWbKE27BhA5ednc1lZ2e7vnd287zpppu4zZs3cwsWLODq1q3L281zzJgx3K5du7hPPvnEsG6e48aN45YvX84dOnSI27p1Kzdu3DjO4XBwf/zxhy2OT4h7ryuOs8dxPvPMM9yyZcu4Q4cOcatWreL69OnD1alThzt9+rRtjjE3N5cLCQnhXn/9dW7fvn3ct99+y0VFRXEzZsxwLWOHvIfjrvS8rV+/Pvfss8/6fGeH33Lo0KFcvXr1XN3Lf/75Z65OnTrc2LFjXcuw9FtSoKORjz76iKtfvz4XFhbGde7cmVu7dq3ZSRK0dOlSDoDPf0OHDuU47krXwBdffJFLTEzkwsPDuRtuuIHbs2ePxzbOnTvH3XPPPVx0dDQXExPDPfDAA1xxcbHHMlu2bOG6d+/OhYeHc/Xq1ePefPNNow6R9/gAcNOmTXMtc+nSJe6xxx7j4uPjuaioKO6OO+7g8vPzPbZz+PBhrn///lxkZCRXp04d7plnnuEqKio8llm6dCnXrl07LiwsjGvYsKHHPvQ0fPhwrkGDBlxYWBhXt25d7oYbbnAFORxn/eMT4h3o2OE47777bi45OZkLCwvj6tWrx919990e48vY4Rg5juP+97//ca1ateLCw8O55s2bc1988YXH93bIeziO437//XcOgE/aOc4ev2VRURE3atQorn79+lxERATXsGFD7vnnn/foBs7Sb+ngOLehDAkhhBBCbITa6BBCCCHEtijQIYQQQohtUaBDCCGEENuiQIcQQgghtkWBDiGEEEJsiwIdQgghhNgWBTqEEEIIsS0KdAghhBBiWzR7OSFEd8uXL8cjjzziMwN5dXU1evbsiY8++ghdunRBWVmZz7olJSXYsWMHJk2ahG+++QYhIZ7ZVnl5OZ5//nkMGTLEZ9077rgDhw4d8vm8tLQU8+fPx9q1a/H6668jLCzM4/vKykrcd999GD16NDIzMxEdHe2zjfDwcKxbt07S8RNCzEOBDiFEd5cuXcLgwYPxyiuveHx++PBhjBs3DgDgcDiwefNmn3V79eoFjuNw4cIFfPzxx+jVq5fH99OnT0dxcTHvfvPz83m3OWzYMFRUVKC4uBhjx47FsGHDPL5ftmwZFixYAI7jkJqaimXLlvlso2vXrkKHSwhhCFVdEUIIIcS2KNAhhBBCiG1RoEMIIYQQ26JAhxBCCCG2RYEOIYQQQmyLAh1CCCGE2BYFOoQQQgixLQp0CCGEEGJbFOgQQgghxLYo0CGEEEKIbdEUEIQQ3cXGxmLu3LmYO3euz3d9+/YFAMTFxSErK4t3/aCgIKSmpuL//u//eL9/7rnneD9v0aKF4DYjIyORkJCAN954Ax9//LHP98OGDUNQUBBKSkp4t1GnTh3e7RJC2OLgOI4zOxGEEEIIIXqgqitCCCGE2BYFOoQQQgixLQp0CCGEEGJbFOgQQgghxLYo0CGEEEKIbVGgQwghhBDbokCHEEIIIbZFgQ4hhBBCbIsCHUIIIYTY1v8DHU2yM6wqisMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "근데 먼가 의미없어보임...."
      ],
      "metadata": {
        "id": "ckmvnFVZqDCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. VIF (다중공산성) 확인**\n",
        "\n",
        "- vif : 분산 팽창 요인\n",
        "\n",
        "- 각 독립 변수가 다른 독립 변수들가 얼마나 강한 상관 관계를 가지는지 측정"
      ],
      "metadata": {
        "id": "hbPmxfkqbww2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = df.columns\n",
        "print(column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1E-xtYmqM7M",
        "outputId": "d4f091f0-bcca-4aad-b9d0-a084194c644e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['전용면적(㎡)', '계약년월', '계약일', '거래금액(만원)', '층', '건축년도', '건설수주_건축(단위 백만원)',\n",
            "       '건설수주_주택(단위 백만원)', '매매가격지수(아파트)', '경상수지(백만불)', '무역수지(백만불)',\n",
            "       '대출금액(아파트)(억원)', '대출잔액(아파트)(억원)', '서울_신규_분양세대(단위: 세대)',\n",
            "       '아파트 동(호)수_(단위: 호)', '아파트 건물면적_(천)', '생산자물가지수 총지수 ',\n",
            "       '전규모(1인이상) 전체임금총액[원]', '소비자물가지수 총지수 ', '소비자물가지수 주택, 수도, 전기 및 연료',\n",
            "       '가계대출 (연리%)', '경기종합지수(2020=100)', '경제활동인구_ 실업률(단위: %)',\n",
            "       '경제활동인구_고용률(단위: %)', '경제활동인구_취업자(단위: 천명)', '국제 주요국 주가지수(KOSPI)',\n",
            "       '예금은행 대출금리(신규취급액 기준)_대출평균(연%)', '예금은행 대출금리(잔액 기준)_총대출(연리%)',\n",
            "       '주택매매가격지수(KB)_서울', '소비자물가지수_총지수(가중치:1000?)',\n",
            "       '원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원', '경기종합지수', '평당가', '매칭 구_강동구',\n",
            "       '매칭 구_강북구', '매칭 구_광진구', '매칭 구_구로구', '매칭 구_노원구', '매칭 구_동대문구', '매칭 구_동작구',\n",
            "       '매칭 구_마포구', '매칭 구_서대문구', '매칭 구_서초구', '매칭 구_성동구', '매칭 구_성북구', '매칭 구_송파구',\n",
            "       '매칭 구_영등포구', '매칭 구_용산구', '매칭 구_은평구', '매칭 구_중구'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected.isnull().sum()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "BjYI5_wNqynV",
        "outputId": "bd1745b6-85a0-4249-cb2a-962f48c72a46"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-170ea00daf49>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_selected' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아파트 건물면적에 107개 NaN 값있어서 평균으로 대체"
      ],
      "metadata": {
        "id": "In15Cbz-rWQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "1_0pVFG5rDiw",
        "outputId": "385f306e-11ba-4044-bb7a-87437409a4dc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           전용면적(㎡)         계약년월          계약일     거래금액(만원)            층  \\\n",
              "count  7862.000000  7862.000000  7862.000000  7862.000000  7862.000000   \n",
              "mean      0.261126     0.246141     0.490791     0.125744     0.222903   \n",
              "std       0.129658     0.303973     0.284900     0.086822     0.155428   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.143211     0.023697     0.266667     0.070862     0.088889   \n",
              "50%       0.274053     0.042654     0.500000     0.107408     0.200000   \n",
              "75%       0.274842     0.492891     0.733333     0.144915     0.311111   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "              건축년도  건설수주_건축(단위 백만원)  건설수주_주택(단위 백만원)  매매가격지수(아파트)  \\\n",
              "count  7862.000000      7862.000000      7862.000000  7862.000000   \n",
              "mean      0.726524         0.402616         0.373241     0.306928   \n",
              "std       0.149914         0.234589         0.222531     0.310334   \n",
              "min       0.000000         0.000000         0.000000     0.000000   \n",
              "25%       0.613636         0.240076         0.234581     0.019417   \n",
              "50%       0.750000         0.357284         0.382739     0.203883   \n",
              "75%       0.840909         0.547543         0.438056     0.475728   \n",
              "max       1.000000         1.000000         1.000000     1.000000   \n",
              "\n",
              "         경상수지(백만불)  ...     매칭 구_마포구    매칭 구_서대문구     매칭 구_서초구     매칭 구_성동구  \\\n",
              "count  7862.000000  ...  7862.000000  7862.000000  7862.000000  7862.000000   \n",
              "mean      0.675461  ...     0.139914     0.073264     0.071483     0.029127   \n",
              "std       0.214931  ...     0.346919     0.260586     0.257646     0.168174   \n",
              "min       0.000000  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.645801  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.687698  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.841300  ...     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000  ...     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "          매칭 구_성북구     매칭 구_송파구    매칭 구_영등포구     매칭 구_용산구     매칭 구_은평구  \\\n",
              "count  7862.000000  7862.000000  7862.000000  7862.000000  7862.000000   \n",
              "mean      0.091707     0.033198     0.049097     0.005088     0.004833   \n",
              "std       0.288630     0.179164     0.216084     0.071151     0.069359   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "           매칭 구_중구  \n",
              "count  7862.000000  \n",
              "mean      0.008522  \n",
              "std       0.091926  \n",
              "min       0.000000  \n",
              "25%       0.000000  \n",
              "50%       0.000000  \n",
              "75%       0.000000  \n",
              "max       1.000000  \n",
              "\n",
              "[8 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13acdf4c-a1d1-445a-9b79-7cc10e5c9a02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>전용면적(㎡)</th>\n",
              "      <th>계약년월</th>\n",
              "      <th>계약일</th>\n",
              "      <th>거래금액(만원)</th>\n",
              "      <th>층</th>\n",
              "      <th>건축년도</th>\n",
              "      <th>건설수주_건축(단위 백만원)</th>\n",
              "      <th>건설수주_주택(단위 백만원)</th>\n",
              "      <th>매매가격지수(아파트)</th>\n",
              "      <th>경상수지(백만불)</th>\n",
              "      <th>...</th>\n",
              "      <th>매칭 구_마포구</th>\n",
              "      <th>매칭 구_서대문구</th>\n",
              "      <th>매칭 구_서초구</th>\n",
              "      <th>매칭 구_성동구</th>\n",
              "      <th>매칭 구_성북구</th>\n",
              "      <th>매칭 구_송파구</th>\n",
              "      <th>매칭 구_영등포구</th>\n",
              "      <th>매칭 구_용산구</th>\n",
              "      <th>매칭 구_은평구</th>\n",
              "      <th>매칭 구_중구</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "      <td>7862.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.261126</td>\n",
              "      <td>0.246141</td>\n",
              "      <td>0.490791</td>\n",
              "      <td>0.125744</td>\n",
              "      <td>0.222903</td>\n",
              "      <td>0.726524</td>\n",
              "      <td>0.402616</td>\n",
              "      <td>0.373241</td>\n",
              "      <td>0.306928</td>\n",
              "      <td>0.675461</td>\n",
              "      <td>...</td>\n",
              "      <td>0.139914</td>\n",
              "      <td>0.073264</td>\n",
              "      <td>0.071483</td>\n",
              "      <td>0.029127</td>\n",
              "      <td>0.091707</td>\n",
              "      <td>0.033198</td>\n",
              "      <td>0.049097</td>\n",
              "      <td>0.005088</td>\n",
              "      <td>0.004833</td>\n",
              "      <td>0.008522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.129658</td>\n",
              "      <td>0.303973</td>\n",
              "      <td>0.284900</td>\n",
              "      <td>0.086822</td>\n",
              "      <td>0.155428</td>\n",
              "      <td>0.149914</td>\n",
              "      <td>0.234589</td>\n",
              "      <td>0.222531</td>\n",
              "      <td>0.310334</td>\n",
              "      <td>0.214931</td>\n",
              "      <td>...</td>\n",
              "      <td>0.346919</td>\n",
              "      <td>0.260586</td>\n",
              "      <td>0.257646</td>\n",
              "      <td>0.168174</td>\n",
              "      <td>0.288630</td>\n",
              "      <td>0.179164</td>\n",
              "      <td>0.216084</td>\n",
              "      <td>0.071151</td>\n",
              "      <td>0.069359</td>\n",
              "      <td>0.091926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.143211</td>\n",
              "      <td>0.023697</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.070862</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>0.240076</td>\n",
              "      <td>0.234581</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.645801</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.274053</td>\n",
              "      <td>0.042654</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.107408</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.357284</td>\n",
              "      <td>0.382739</td>\n",
              "      <td>0.203883</td>\n",
              "      <td>0.687698</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.274842</td>\n",
              "      <td>0.492891</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.144915</td>\n",
              "      <td>0.311111</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0.547543</td>\n",
              "      <td>0.438056</td>\n",
              "      <td>0.475728</td>\n",
              "      <td>0.841300</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13acdf4c-a1d1-445a-9b79-7cc10e5c9a02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-13acdf4c-a1d1-445a-9b79-7cc10e5c9a02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-13acdf4c-a1d1-445a-9b79-7cc10e5c9a02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cb837a9f-7346-4bbb-a309-6873e1474091\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb837a9f-7346-4bbb-a309-6873e1474091')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cb837a9f-7346-4bbb-a309-6873e1474091 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 열의 평균값 계산\n",
        "column_name = '아파트 건물면적_(천)'  # 대체할 열의 이름으로 변경\n",
        "mean_value = df[column_name].mean()\n",
        "\n",
        "# NaN 값에 평균값 대체\n",
        "df[column_name].fillna(mean_value, inplace=True)\n"
      ],
      "metadata": {
        "id": "aH22_N98rU7v"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df\n",
        "df2 = df"
      ],
      "metadata": {
        "id": "DisstP_lshnr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# 데이터프레임에서 불필요한 변수 제거\n",
        "selected_columns = ['전용면적(㎡)', '계약년월', '계약일', '거래금액(만원)', '층', '건축년도', '건설수주_건축(단위 백만원)',\n",
        "       '건설수주_주택(단위 백만원)', '매매가격지수(아파트)', '경상수지(백만불)', '무역수지(백만불)',\n",
        "       '대출금액(아파트)(억원)', '대출잔액(아파트)(억원)', '서울_신규_분양세대(단위: 세대)',\n",
        "       '아파트 동(호)수_(단위: 호)', '아파트 건물면적_(천)', '생산자물가지수 총지수 ',\n",
        "       '전규모(1인이상) 전체임금총액[원]', '소비자물가지수 총지수 ', '소비자물가지수 주택, 수도, 전기 및 연료',\n",
        "       '가계대출 (연리%)', '경기종합지수(2020=100)', '경제활동인구_ 실업률(단위: %)',\n",
        "       '경제활동인구_고용률(단위: %)', '경제활동인구_취업자(단위: 천명)', '국제 주요국 주가지수(KOSPI)',\n",
        "       '예금은행 대출금리(신규취급액 기준)_대출평균(연%)', '예금은행 대출금리(잔액 기준)_총대출(연리%)',\n",
        "       '주택매매가격지수(KB)_서울', '소비자물가지수_총지수(가중치:1000?)',\n",
        "       '원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원', '경기종합지수']  # 분석에 필요한 변수들을 선택\n",
        "df1_selected = df1[selected_columns]\n",
        "\n",
        "# VIF 계산\n",
        "def calculate_vif(data_frame):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variable\"] = data_frame.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(data_frame.values, i) for i in range(data_frame.shape[1])]\n",
        "    return vif_data.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "\n",
        "vif_result = calculate_vif(df1_selected)\n",
        "\n",
        "\n",
        "\n",
        "# VIF가 높은 변수 확인\n",
        "high_vif_variables = vif_result[vif_result['VIF'] > 5]['Variable'].tolist()\n",
        "print(f'다중공산성이 높은 변수: {high_vif_variables}')\n",
        "\n",
        "# 불필요한 변수 제거\n",
        "df1_final = df1_selected.drop(columns=high_vif_variables, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRT7MHiVri_U",
        "outputId": "d2fbc8ec-6ae9-48ef-d4d6-c981f9f6130f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  vif = 1. / (1. - r_squared_i)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다중공산성이 높은 변수: ['전용면적(㎡)', '계약년월', '거래금액(만원)', '건축년도', '건설수주_건축(단위 백만원)', '건설수주_주택(단위 백만원)', '매매가격지수(아파트)', '경상수지(백만불)', '무역수지(백만불)', '대출금액(아파트)(억원)', '대출잔액(아파트)(억원)', '서울_신규_분양세대(단위: 세대)', '아파트 동(호)수_(단위: 호)', '아파트 건물면적_(천)', '생산자물가지수 총지수 ', '전규모(1인이상) 전체임금총액[원]', '소비자물가지수 주택, 수도, 전기 및 연료', '가계대출 (연리%)', '경제활동인구_ 실업률(단위: %)', '경제활동인구_고용률(단위: %)', '경제활동인구_취업자(단위: 천명)', '국제 주요국 주가지수(KOSPI)', '예금은행 대출금리(신규취급액 기준)_대출평균(연%)', '예금은행 대출금리(잔액 기준)_총대출(연리%)', '주택매매가격지수(KB)_서울', '원화의 대미달러, 원화의 대위안/대엔 환율(원/달러(종가)_원']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wYM4wusersNY",
        "outputId": "f94ec641-b57f-4922-dddb-0278a4587f7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           계약일         층  소비자물가지수 총지수   경기종합지수(2020=100)  \\\n",
              "0     0.533333  0.133333      0.162602          0.482456   \n",
              "1     0.700000  0.377778      0.265244          0.701754   \n",
              "2     0.700000  0.133333      0.265244          0.701754   \n",
              "3     0.700000  0.377778      0.265244          0.701754   \n",
              "4     0.700000  0.133333      0.265244          0.701754   \n",
              "...        ...       ...           ...               ...   \n",
              "7857  0.900000  0.088889      0.066057          0.377193   \n",
              "7858  0.000000  0.088889      0.090447          0.421053   \n",
              "7859  0.133333  0.266667      0.090447          0.421053   \n",
              "7860  0.300000  0.022222      0.090447          0.421053   \n",
              "7861  0.500000  0.200000      0.090447          0.421053   \n",
              "\n",
              "      소비자물가지수_총지수(가중치:1000?)    경기종합지수  \n",
              "0                   0.162602  0.482456  \n",
              "1                   0.265244  0.701754  \n",
              "2                   0.265244  0.701754  \n",
              "3                   0.265244  0.701754  \n",
              "4                   0.265244  0.701754  \n",
              "...                      ...       ...  \n",
              "7857                0.066057  0.377193  \n",
              "7858                0.090447  0.421053  \n",
              "7859                0.090447  0.421053  \n",
              "7860                0.090447  0.421053  \n",
              "7861                0.090447  0.421053  \n",
              "\n",
              "[7862 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e53d0d0d-6ad4-4bb0-837c-a0b803402e87\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>계약일</th>\n",
              "      <th>층</th>\n",
              "      <th>소비자물가지수 총지수</th>\n",
              "      <th>경기종합지수(2020=100)</th>\n",
              "      <th>소비자물가지수_총지수(가중치:1000?)</th>\n",
              "      <th>경기종합지수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.162602</td>\n",
              "      <td>0.482456</td>\n",
              "      <td>0.162602</td>\n",
              "      <td>0.482456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.377778</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.377778</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "      <td>0.265244</td>\n",
              "      <td>0.701754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7857</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.066057</td>\n",
              "      <td>0.377193</td>\n",
              "      <td>0.066057</td>\n",
              "      <td>0.377193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7858</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088889</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7859</th>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7860</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7861</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "      <td>0.090447</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7862 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e53d0d0d-6ad4-4bb0-837c-a0b803402e87')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e53d0d0d-6ad4-4bb0-837c-a0b803402e87 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e53d0d0d-6ad4-4bb0-837c-a0b803402e87');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-980b1a45-131a-4e05-904e-f5b114c1f096\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-980b1a45-131a-4e05-904e-f5b114c1f096')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-980b1a45-131a-4e05-904e-f5b114c1f096 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 vif 로 걸러진 데이터프레임에\n",
        "\n",
        "매칭구 (원핫인코딩) + 평당가 (타겟변수) 추가한 최종 데이터프레임 만든다."
      ],
      "metadata": {
        "id": "g-h_c8bLr3jM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataFrame에 새로운 열 추가\n",
        "add = ['평당가', '매칭 구_강동구',\n",
        "       '매칭 구_강북구', '매칭 구_광진구', '매칭 구_구로구', '매칭 구_노원구', '매칭 구_동대문구', '매칭 구_동작구',\n",
        "       '매칭 구_마포구', '매칭 구_서대문구', '매칭 구_서초구', '매칭 구_성동구', '매칭 구_성북구', '매칭 구_송파구',\n",
        "       '매칭 구_영등포구', '매칭 구_용산구', '매칭 구_은평구', '매칭 구_중구']\n",
        "\n",
        "df_combined = pd.concat([df1_final, df2[add]], axis=1)\n",
        "\n",
        "# 합쳐진 데이터프레임 확인\n",
        "print(df_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZuJK_xrsBya",
        "outputId": "60d71482-e96f-45ca-843d-6afc545f1254"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           계약일         층  소비자물가지수 총지수   경기종합지수(2020=100)  \\\n",
            "0     0.533333  0.133333      0.162602          0.482456   \n",
            "1     0.700000  0.377778      0.265244          0.701754   \n",
            "2     0.700000  0.133333      0.265244          0.701754   \n",
            "3     0.700000  0.377778      0.265244          0.701754   \n",
            "4     0.700000  0.133333      0.265244          0.701754   \n",
            "...        ...       ...           ...               ...   \n",
            "7857  0.900000  0.088889      0.066057          0.377193   \n",
            "7858  0.000000  0.088889      0.090447          0.421053   \n",
            "7859  0.133333  0.266667      0.090447          0.421053   \n",
            "7860  0.300000  0.022222      0.090447          0.421053   \n",
            "7861  0.500000  0.200000      0.090447          0.421053   \n",
            "\n",
            "      소비자물가지수_총지수(가중치:1000?)    경기종합지수          평당가  매칭 구_강동구  매칭 구_강북구  \\\n",
            "0                   0.162602  0.482456  3281.542995         0         0   \n",
            "1                   0.265244  0.701754  3312.750334         0         0   \n",
            "2                   0.265244  0.701754  3605.769231         0         0   \n",
            "3                   0.265244  0.701754  3312.750334         0         0   \n",
            "4                   0.265244  0.701754  3605.769231         0         0   \n",
            "...                      ...       ...          ...       ...       ...   \n",
            "7857                0.066057  0.377193  1740.877134         0         0   \n",
            "7858                0.090447  0.421053  1707.398728         0         0   \n",
            "7859                0.090447  0.421053  1774.355541         0         0   \n",
            "7860                0.090447  0.421053  1506.236762         0         0   \n",
            "7861                0.090447  0.421053  1488.760739         0         0   \n",
            "\n",
            "      매칭 구_광진구  ...  매칭 구_마포구  매칭 구_서대문구  매칭 구_서초구  매칭 구_성동구  매칭 구_성북구  \\\n",
            "0            0  ...         0          0         0         0         0   \n",
            "1            0  ...         0          0         0         0         0   \n",
            "2            0  ...         0          0         0         0         0   \n",
            "3            0  ...         0          0         0         0         0   \n",
            "4            0  ...         0          0         0         0         0   \n",
            "...        ...  ...       ...        ...       ...       ...       ...   \n",
            "7857         0  ...         0          0         0         0         0   \n",
            "7858         0  ...         0          0         0         0         0   \n",
            "7859         0  ...         0          0         0         0         0   \n",
            "7860         0  ...         0          0         0         0         0   \n",
            "7861         0  ...         0          0         0         0         0   \n",
            "\n",
            "      매칭 구_송파구  매칭 구_영등포구  매칭 구_용산구  매칭 구_은평구  매칭 구_중구  \n",
            "0            0          0         0         0        0  \n",
            "1            0          0         0         0        0  \n",
            "2            0          0         0         0        0  \n",
            "3            0          0         0         0        0  \n",
            "4            0          0         0         0        0  \n",
            "...        ...        ...       ...       ...      ...  \n",
            "7857         0          0         0         0        1  \n",
            "7858         0          0         0         0        1  \n",
            "7859         0          0         0         0        1  \n",
            "7860         0          0         0         0        1  \n",
            "7861         0          0         0         0        1  \n",
            "\n",
            "[7862 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df_combined"
      ],
      "metadata": {
        "id": "_spo8vDruV57"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = data.columns\n",
        "print(column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThJfD6axu689",
        "outputId": "7e8c61cb-5f85-42a7-866a-583ae70650f7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['계약일', '층', '소비자물가지수 총지수 ', '경기종합지수(2020=100)',\n",
            "       '소비자물가지수_총지수(가중치:1000?)', '경기종합지수', '평당가', '매칭 구_강동구', '매칭 구_강북구',\n",
            "       '매칭 구_광진구', '매칭 구_구로구', '매칭 구_노원구', '매칭 구_동대문구', '매칭 구_동작구', '매칭 구_마포구',\n",
            "       '매칭 구_서대문구', '매칭 구_서초구', '매칭 구_성동구', '매칭 구_성북구', '매칭 구_송파구',\n",
            "       '매칭 구_영등포구', '매칭 구_용산구', '매칭 구_은평구', '매칭 구_중구'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. 모델 학습**"
      ],
      "metadata": {
        "id": "3v7_xWWYuZyS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "아파트 평당가 예측은 회귀 문제\n",
        "\n",
        "-> MSE, R^2 값으로만 모델의 성능 평가\n",
        "\n",
        "분류 문제일때 예측도 (%) 로 성능을 평가함\n",
        "\n",
        "**R-squared 값이 0.7 이상이면 좋은 성능으로 판단**"
      ],
      "metadata": {
        "id": "WdAn7RHuyF7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cross validation**"
      ],
      "metadata": {
        "id": "syt9hP_yur0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "p3V-8_HfuoOI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# features와 target 정의\n",
        "features = data[[ '계약일', '층', '소비자물가지수 총지수 ', '경기종합지수(2020=100)',\n",
        "       '소비자물가지수_총지수(가중치:1000?)', '경기종합지수', '매칭 구_강동구', '매칭 구_강북구',\n",
        "       '매칭 구_광진구', '매칭 구_구로구', '매칭 구_노원구', '매칭 구_동대문구', '매칭 구_동작구', '매칭 구_마포구',\n",
        "       '매칭 구_서대문구', '매칭 구_서초구', '매칭 구_성동구', '매칭 구_성북구', '매칭 구_송파구',\n",
        "       '매칭 구_영등포구', '매칭 구_용산구', '매칭 구_은평구', '매칭 구_중구' ]]\n",
        "\n",
        "target = data['평당가']\n",
        "\n",
        "# 전체 데이터를 train/validation과 test로 나누기\n",
        "X_train_valid, X_test, y_train_valid, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# 다시 train과 validation으로 나누기\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YLSECfiluvu8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-1. 랜덤 포레스트**"
      ],
      "metadata": {
        "id": "h6f9FeZEueSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "# 랜덤 포레스트 모델 생성\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 탐색할 하이퍼파라미터 값 지정\n",
        "param_grid = {\n",
        "    'n_estimators': [200],  # 트리 개수 - 우리가 쓴 데이터의 경우 중간 규모이므로 1000보다 큰 걸 쓰는 게 일반적으론 권장됨\n",
        "                                  # 보통 100, 200 부터 증가시키면서 성능이 최대일 때 멈춤.\n",
        "    'max_depth': [10, 1, 0.1], # esimator 빼고 나머지 3개는 로그 스케일로 확인하는 게 좋음. -> 로그 단위의 1, 2, 3 이렇게가 공평해서\n",
        "    'min_samples_split': [0.1, 1, 10, 100],\n",
        "    'min_samples_leaf': [0.001]\n",
        "}\n",
        "\n",
        "# 그리드 서치 객체 생성\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=2)\n",
        "\n",
        "# 그리드 서치 수행\n",
        "grid_search.fit(X_train_valid, y_train_valid)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적의 모델을 얻어옴\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# 검증 데이터에 대한 평가 (MSE)\n",
        "y_valid_pred = best_rf_model.predict(X_valid)\n",
        "mse = mean_squared_error(y_valid, y_valid_pred)\n",
        "print(f'Mean Squared Error on Validation Data: {mse}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가\n",
        "cv_scores = cross_val_score(best_rf_model, X_train_valid, y_train_valid, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "print(f'Mean Squared Error with Cross-Validation: {cv_mse}')\n",
        "\n",
        "\n",
        "\n",
        "# 검증 데이터에 대한 평가 (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error on Validation Data: {rmse}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 (RMSE)\n",
        "cv_rmse = np.sqrt(-cv_scores.mean())\n",
        "print(f'Root Mean Squared Error with Cross-Validation: {cv_rmse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lnS3sbKudo-",
        "outputId": "6a8d900c-6b17-4c35-8e9a-aafd8527e35c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   1.5s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   1.5s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   1.5s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   1.5s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   2.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   2.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   1.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   1.7s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   1.7s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   3.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   4.6s\n",
            "[CV] END max_depth=10, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   2.3s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   1.0s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, min_samples_leaf=0.001, min_samples_split=100, n_estimators=200; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "20 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0.1 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-239062.63323398              nan -223631.7977266  -224670.56447847\n",
            " -371535.1423151               nan -371535.1423151  -371535.1423151\n",
            "              nan              nan              nan              nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 0.001, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Mean Squared Error on Validation Data: 202229.48742359344\n",
            "Mean Squared Error with Cross-Validation: 223631.7977266001\n",
            "Root Mean Squared Error on Validation Data: 449.6993300235096\n",
            "Root Mean Squared Error with Cross-Validation: 472.89723801963584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, explained_variance_score\n",
        "\n",
        "# 최적의 모델을 얻어옴\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# 검증 데이터에 대한 평가 (R^2)\n",
        "y_valid_pred = best_rf_model.predict(X_valid)\n",
        "r2 = r2_score(y_valid, y_valid_pred)\n",
        "print(f'R^2 on Validation Data: {r2}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 (R^2)\n",
        "cv_scores_r2 = cross_val_score(best_rf_model, X_train_valid, y_train_valid, cv=5, scoring='r2')\n",
        "cv_r2 = cv_scores_r2.mean()\n",
        "print(f'R^2 with Cross-Validation: {cv_r2}')\n",
        "\n",
        "# 검증 데이터에 대한 평가 (Explained Variance)\n",
        "explained_var = explained_variance_score(y_valid, y_valid_pred)\n",
        "print(f'Explained Variance on Validation Data: {explained_var}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 (Explained Variance)\n",
        "cv_scores_explained_var = cross_val_score(best_rf_model, X_train_valid, y_train_valid, cv=5, scoring='explained_variance')\n",
        "cv_explained_var = cv_scores_explained_var.mean()\n",
        "print(f'Explained Variance with Cross-Validation: {cv_explained_var}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pMoNbi0vOxC",
        "outputId": "e1edd540-27e7-4697-8d8f-56bcf342d5bc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 on Validation Data: 0.5572166952332855\n",
            "R^2 with Cross-Validation: 0.5064140894988837\n",
            "Explained Variance on Validation Data: 0.5572474777498054\n",
            "Explained Variance with Cross-Validation: 0.5076458427788161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "과적합 해결을 위해 '규제' 적용"
      ],
      "metadata": {
        "id": "EFngHkrm2X9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# 랜덤 포레스트 모델 생성\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 탐색할 하이퍼파라미터 값 지정\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [0.1, 1, 10],\n",
        "    'min_samples_split': [0.1, 1, 10],\n",
        "    'min_samples_leaf': [0.01, 0.1, 1],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# 그리드 서치 객체 생성\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           scoring='neg_mean_squared_error', cv=5, verbose=2)\n",
        "\n",
        "# 그리드 서치 수행\n",
        "grid_search.fit(X_train_valid, y_train_valid)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# 최적의 모델을 얻어옴\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# 검증 데이터에 대한 평가 (MSE)\n",
        "y_valid_pred = best_rf_model.predict(X_valid)\n",
        "mse = mean_squared_error(y_valid, y_valid_pred)\n",
        "print(f'Mean Squared Error on Validation Data: {mse}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가\n",
        "cv_scores = cross_val_score(best_rf_model, X_train_valid, y_train_valid, cv=5, scoring='neg_mean_squared_error')\n",
        "cv_mse = -cv_scores.mean()\n",
        "print(f'Mean Squared Error with Cross-Validation: {cv_mse}')\n",
        "\n",
        "# 검증 데이터에 대한 평가 (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error on Validation Data: {rmse}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 (RMSE)\n",
        "cv_rmse = np.sqrt(-cv_scores.mean())\n",
        "print(f'Root Mean Squared Error with Cross-Validation: {cv_rmse}')\n",
        "\n",
        "# 검증 데이터에 대한 평가 (R-squared)\n",
        "r2 = r2_score(y_valid, y_valid_pred)\n",
        "print(f'R^2 on Validation Data: {r2}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 (R-squared)\n",
        "cv_r2_scores = cross_val_score(best_rf_model, X_train_valid, y_train_valid, cv=5, scoring='r2')\n",
        "cv_r2 = cv_r2_scores.mean()\n",
        "print(f'R^2 with Cross-Validation: {cv_r2}')\n",
        "\n",
        "# 검증 데이터에 대한 평가 (Explained Variance)\n",
        "explained_variance = explained_variance_score(y_valid, y_valid_pred)\n",
        "print(f'Explained Variance on Validation Data: {explained_variance}')\n",
        "\n",
        "# 교차 검증을 통한 모델 평가 (Explained Variance)\n",
        "cv_explained_variance_scores = cross_val_score(best_rf_model, X_train_valid, y_train_valid, cv=5, scoring='explained_variance')\n",
        "cv_explained_variance = cv_explained_variance_scores.mean()\n",
        "print(f'Explained Variance with Cross-Validation: {cv_explained_variance}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq9Rb_gm2bg0",
        "outputId": "6c67303b-6254-4da1-bb9b-540bf304e410"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=0.1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   1.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   1.7s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.7s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.0s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   1.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=1, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
            "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.8s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=0.1, n_estimators=200; total time=   0.5s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.01, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=0.1, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=100; total time=   0.2s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=0.1, min_samples_split=10, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.9s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=0.1, n_estimators=200; total time=   0.6s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=100; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=1, n_estimators=200; total time=   0.0s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   0.3s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n",
            "[CV] END max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   0.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "300 fits failed out of a total of 540.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "180 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_depth' parameter of RandomForestRegressor must be an int in the range [1, inf) or None. Got 0.1 instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "120 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\", line 340, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of RandomForestRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [             nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            " -398734.44838272 -398362.5479159               nan              nan\n",
            " -398734.44838272 -398362.5479159  -423581.02828717 -423280.26699963\n",
            "              nan              nan -423581.02828717 -423280.26699963\n",
            " -398565.444457   -398114.59716853              nan              nan\n",
            " -398565.444457   -398114.59716853 -398734.44838272 -398362.5479159\n",
            "              nan              nan -398734.44838272 -398362.5479159\n",
            " -423581.02828717 -423280.26699963              nan              nan\n",
            " -423581.02828717 -423280.26699963 -398565.444457   -398114.59716853\n",
            "              nan              nan -398565.444457   -398114.59716853\n",
            " -284526.71678758 -284309.79123582              nan              nan\n",
            " -277359.58753582 -276777.45000837 -416432.01572752 -416231.9158563\n",
            "              nan              nan -416432.01572752 -416231.9158563\n",
            " -266912.45700149 -265115.99156228              nan              nan\n",
            " -238917.57048056 -237995.87957826 -284526.71678758 -284309.79123582\n",
            "              nan              nan -277359.58753582 -276777.45000837\n",
            " -416432.01572752 -416231.9158563               nan              nan\n",
            " -416432.01572752 -416231.9158563  -266912.45700149 -265115.99156228\n",
            "              nan              nan -238917.57048056 -237995.87957826]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
            "Mean Squared Error on Validation Data: 215583.6493371964\n",
            "Mean Squared Error with Cross-Validation: 237995.87957826303\n",
            "Root Mean Squared Error on Validation Data: 464.3098634933318\n",
            "Root Mean Squared Error with Cross-Validation: 487.8482136671846\n",
            "R^2 on Validation Data: 0.5279776360840654\n",
            "R^2 with Cross-Validation: 0.47676175198179493\n",
            "Explained Variance on Validation Data: 0.5279803628718416\n",
            "Explained Variance with Cross-Validation: 0.47806451101396413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-2. XGBoost**"
      ],
      "metadata": {
        "id": "Ssh5IrXfvQtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 특성(X)과 타겟 변수(y) 선택\n",
        "# 특성: 예측에 사용되는 변수들\n",
        "# 타겟 변수: 예측하려는 변수\n",
        "X = data.drop('평당가', axis=1)\n",
        "y = data['평당가']\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 나눔\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# XGBoost 모델 생성\n",
        "model = XGBRegressor()\n",
        "\n",
        "# GridSearchCV를 위한 하이퍼파라미터 그리드 설정\n",
        "param_grid = {\n",
        "    'n_estimators': [200, 500],\n",
        "    'learning_rate': [0.1, 1, 10],\n",
        "    'max_depth': [0.1, 1, 10],\n",
        "    'min_child_weight': [0.001, 0.1, 1]\n",
        "}\n",
        "\n",
        "# GridSearchCV 객체 생성\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "best_params = grid_search.best_params_\n",
        "print(f'최적의 하이퍼파라미터: {best_params}')\n",
        "\n",
        "# 최적의 모델\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 테스트 세트 예측\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# 모델 평가 - 평균제곱오차(MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "\n",
        "# 모델 평가 - 평균제곱근오차(RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "\n",
        "# 모델 평가 - 결정계수(R^2)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# 예측 결과 확인\n",
        "result_df = pd.DataFrame({'실제값': y_test, '예측값': y_pred})\n",
        "\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa58Stjevs8c",
        "outputId": "fbaa3cdb-b2ef-42d8-d755-182537c59237"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 442, in mean_squared_error\n",
            "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py\", line 102, in _check_reg_targets\n",
            "    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
            "    _assert_all_finite(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
            "    raise ValueError(msg_err)\n",
            "ValueError: Input contains NaN.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "90 fits failed out of a total of 270.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\", line 1086, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/training.py\", line 181, in train\n",
            "    bst.update(dtrain, i, obj)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 2049, in update\n",
            "    _check_call(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/xgboost/core.py\", line 281, in _check_call\n",
            "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
            "xgboost.core.XGBoostError: Invalid Parameter format for max_depth expect int but value='0.1'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [             nan              nan              nan              nan\n",
            "              nan              nan -236562.49615298 -209108.66290101\n",
            " -236562.49615298 -209108.66290101 -236562.49615298 -209108.66290101\n",
            " -183807.91709341 -200496.39707345 -183807.91709341 -200496.39707345\n",
            " -183807.91709341 -200496.39707345              nan              nan\n",
            "              nan              nan              nan              nan\n",
            " -173782.52348927 -172712.49740375 -173782.52348927 -172712.49740375\n",
            " -173782.52348927 -172712.49740375 -278832.43948697 -278835.71545051\n",
            " -278832.43948697 -278835.71545051 -278832.43948697 -278835.71545051\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan              nan              nan\n",
            "              nan              nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터: {'learning_rate': 1, 'max_depth': 1, 'min_child_weight': 0.001, 'n_estimators': 500}\n",
            "Mean Squared Error (MSE): 185280.70457002227\n",
            "Root Mean Squared Error (RMSE): 430.44245210018755\n",
            "R^2 Score: 0.5922330141728913\n",
            "              실제값          예측값\n",
            "1242  1709.401709  1479.451294\n",
            "1407   941.332450  2752.542480\n",
            "2579  1296.488369  1745.490234\n",
            "1075  1663.306452  1747.535767\n",
            "5448  2559.800953  1840.359375\n",
            "...           ...          ...\n",
            "196   1861.012956  1894.175293\n",
            "4466   937.692782  1168.202393\n",
            "3515  2114.701404  2455.581055\n",
            "415   1012.658228  1265.742065\n",
            "2571  1426.459076  1832.117432\n",
            "\n",
            "[1573 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-3. SVR**"
      ],
      "metadata": {
        "id": "z_x3pwgHvVPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# 특성(X)과 타겟 변수(y) 선택\n",
        "X = data.drop('평당가', axis=1)\n",
        "y = data['평당가']\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 나눔\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# SVM 모델 생성 (SVR로 변경)\n",
        "model = SVR()\n",
        "\n",
        "# GridSearchCV를 위한 하이퍼파라미터 그리드 설정\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "# GridSearchCV 객체 생성\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 최적의 하이퍼파라미터 출력\n",
        "best_params = grid_search.best_params_\n",
        "print(f'최적의 하이퍼파라미터: {best_params}')\n",
        "\n",
        "# 최적의 모델\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# 테스트 세트 예측\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# 모델 평가 - 평균제곱오차(MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "\n",
        "# 모델 평가 - 평균제곱근오차(RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "\n",
        "# 모델 평가 - 결정계수(R^2)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# 예측 결과 확인\n",
        "result_df = pd.DataFrame({'실제값': y_test, '예측값': y_pred})\n",
        "\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40mUJFRT4oTC",
        "outputId": "4857e20c-5bfe-4cd9-f00c-67402b16c9a9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적의 하이퍼파라미터: {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
            "Mean Squared Error (MSE): 228598.25506810693\n",
            "Root Mean Squared Error (RMSE): 478.11949873238484\n",
            "R^2 Score: 0.4968994658629966\n",
            "              실제값          예측값\n",
            "1242  1709.401709  1555.050103\n",
            "1407   941.332450  2362.030475\n",
            "2579  1296.488369  1608.568250\n",
            "1075  1663.306452  1875.330196\n",
            "5448  2559.800953  1889.374792\n",
            "...           ...          ...\n",
            "196   1861.012956  1972.619401\n",
            "4466   937.692782  1138.652477\n",
            "3515  2114.701404  2120.039531\n",
            "415   1012.658228  1257.431899\n",
            "2571  1426.459076  1621.658576\n",
            "\n",
            "[1573 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-4. 앙상블 모델**\n",
        "\n",
        "모델의 복잡성을 줄이기 위해 사용하므로 랜덤 포레스트 + 그래디언트 부스팅으로 만듦\n",
        "\n",
        " + 가장 성능이 좋았던 XGBoost"
      ],
      "metadata": {
        "id": "Oku5FDRKvc5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# 데이터를 특성(X)과 타겟 변수(y)로 나누기\n",
        "X = data.drop('평당가', axis=1)\n",
        "y = data['평당가']\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 랜덤 포레스트 모델 생성\n",
        "rf_model = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
        "\n",
        "# XGBoost 모델 생성\n",
        "xgb_model = XGBRegressor(n_estimators=300, max_depth=10, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Gradient Boosting 모델 생성\n",
        "gb_model = GradientBoostingRegressor(n_estimators=300, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
        "\n",
        "# 앙상블 모델 생성\n",
        "ensemble_model = VotingRegressor(estimators=[('rf', rf_model), ('xgb', xgb_model), ('gb', gb_model)])\n",
        "\n",
        "# 모델 훈련\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트 예측\n",
        "y_pred = ensemble_model.predict(X_test)\n",
        "\n",
        "# 모델 평가 - 평균제곱오차(MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error (MSE): {mse}')\n",
        "\n",
        "# 모델 평가 - 평균제곱근오차(RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
        "\n",
        "# 모델 평가 - 결정계수(R^2)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R^2 Score: {r2}')\n",
        "\n",
        "# 예측 결과 확인\n",
        "result_df = pd.DataFrame({'실제값': y_test, '예측값': y_pred})\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtXicHA7xcGJ",
        "outputId": "d5de9379-bb68-4b79-dd73-748dc0691f25"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 202211.53081939433\n",
            "Root Mean Squared Error (RMSE): 449.67936445804844\n",
            "R^2 Score: 0.5549715410837721\n",
            "              실제값          예측값\n",
            "1242  1709.401709  1611.540184\n",
            "1407   941.332450  2536.158796\n",
            "2579  1296.488369  1604.027137\n",
            "1075  1663.306452  1993.519287\n",
            "5448  2559.800953  1978.737139\n",
            "...           ...          ...\n",
            "196   1861.012956  2057.047211\n",
            "4466   937.692782  1296.466231\n",
            "3515  2114.701404  2162.316404\n",
            "415   1012.658228  1425.361424\n",
            "2571  1426.459076  1861.319816\n",
            "\n",
            "[1573 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}